{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow-RussianDolls.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "1ilOvhjA3xS1",
        "WguU1NgEsCL6",
        "DskmJEsu8xdX",
        "QDDm6TsK34PC",
        "ItXfxkxvosLH",
        "NvoiEwiAWrWy",
        "Aa-KnZKcfvkV",
        "yVLSSAUViyiX",
        "W3G5sZ3yo-yK",
        "ggjuE4es7SDH"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahgift/managed_ml_systems_and_iot/blob/master/TensorFlow_RussianDolls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dRxWhH0g3tKF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Russian Dolls\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EggdJbEp6Pak",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![wikipedia_commons](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Russian_Dolls.jpg/640px-Russian_Dolls.jpg)\n",
        "\n",
        "[*source:  wikipedia*](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Russian_Dolls.jpg/640px-Russian_Dolls.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "g5uaujBRJ7Z9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A *crash course* involving several layers of abstraction with [TensorFlow](https://www.tensorflow.org/)"
      ]
    },
    {
      "metadata": {
        "id": "1ilOvhjA3xS1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TensorFlow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WguU1NgEsCL6"
      },
      "cell_type": "markdown",
      "source": [
        "### TensorFlow Hello World"
      ]
    },
    {
      "metadata": {
        "id": "oDpT_ks65v4J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "References\n",
        "\n",
        "*  [Official Hello World Example]( https://colab.research.google.com/notebooks/welcome.ipynb#scrollTo=oYZkU7ZN3CL0)\n",
        "*  Adds two matrices\n"
      ]
    },
    {
      "metadata": {
        "id": "5iX0wEVI6t49",
        "colab_type": "code",
        "outputId": "6e073204-6964-493f-fc9c-81948b4d1f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "input1 = tf.ones((2, 3))\n",
        "input2 = tf.reshape(tf.range(1, 7, dtype=tf.float32), (2, 3))\n",
        "\n",
        "print(\"Two Tensor Flow Matrices with shape:\")\n",
        "print(input1.shape)\n",
        "print(input2.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Two Tensor Flow Matrices with shape:\n",
            "(2, 3)\n",
            "(2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "afyOLD6p5l3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "9570c763-b793-4b5f-d332-7bcb42e046d4"
      },
      "cell_type": "code",
      "source": [
        "output = input1 + input2\n",
        "with tf.Session():\n",
        "  result = output.eval()\n",
        "\n",
        "print(f\"Type of result:  {type(result)}\\n\")\n",
        "print(\"Result of addition of two Matrics:\")\n",
        "result\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of result:  <class 'numpy.ndarray'>\n",
            "\n",
            "Result of addition of two Matrics:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 3., 4.],\n",
              "       [5., 6., 7.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "ng1Yv1pXUhWk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tensorflow Linear Regression (Project)"
      ]
    },
    {
      "metadata": {
        "id": "xZdpALUHUw6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Based *on official Google Tutorial [here](https://developers.google.com/machine-learning/crash-course/first-steps-with-tensorflow/programming-exercises)*"
      ]
    },
    {
      "metadata": {
        "id": "Bd2Zkk1LE2Zr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives:**\n",
        "  * Learn fundamental TensorFlow concepts\n",
        "  * Use the `LinearRegressor` class in TensorFlow to predict median housing price, at the granularity of city blocks, based on one input feature\n",
        "  * Evaluate the accuracy of a model's predictions using Root Mean Squared Error (RMSE)\n",
        "  * Improve the accuracy of a model by tuning its hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "MxiIKhP4E2Zr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The [data](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) is based on 1990 census data from California."
      ]
    },
    {
      "metadata": {
        "id": "6TjLjL9IU80G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Setup\n",
        "In this first cell, we'll load the necessary libraries."
      ]
    },
    {
      "metadata": {
        "id": "rVFf5asKE2Zt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ipRyUHjhU80Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we'll load our data set."
      ]
    },
    {
      "metadata": {
        "id": "9ivCDWnwE2Zx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vVk_qlG6U80j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll randomize the data, just to be sure not to get any pathological ordering effects that might harm the performance of Stochastic Gradient Descent. Additionally, we'll scale `median_house_value` to be in units of thousands, so it can be learned a little more easily with learning rates in a range that we usually use."
      ]
    },
    {
      "metadata": {
        "id": "r0eVyguIU80m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "76bed552-d2dc-48e7-edf3-caba0796e7c3"
      },
      "cell_type": "code",
      "source": [
        "california_housing_dataframe = california_housing_dataframe.reindex(\n",
        "    np.random.permutation(california_housing_dataframe.index))\n",
        "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
        "california_housing_dataframe"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14948</th>\n",
              "      <td>-122.2</td>\n",
              "      <td>37.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1617.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>758.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>469.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6812</th>\n",
              "      <td>-118.3</td>\n",
              "      <td>34.1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2107.0</td>\n",
              "      <td>757.0</td>\n",
              "      <td>2660.0</td>\n",
              "      <td>740.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>282.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14564</th>\n",
              "      <td>-122.2</td>\n",
              "      <td>37.9</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1779.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>721.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>434.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9273</th>\n",
              "      <td>-119.1</td>\n",
              "      <td>35.4</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2044.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>894.0</td>\n",
              "      <td>359.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>82.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7940</th>\n",
              "      <td>-118.4</td>\n",
              "      <td>34.3</td>\n",
              "      <td>38.0</td>\n",
              "      <td>858.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>1250.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>137.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6189</th>\n",
              "      <td>-118.2</td>\n",
              "      <td>34.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1204.0</td>\n",
              "      <td>552.0</td>\n",
              "      <td>1074.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>87.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6963</th>\n",
              "      <td>-118.3</td>\n",
              "      <td>34.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1555.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>105.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>-117.3</td>\n",
              "      <td>33.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4632.0</td>\n",
              "      <td>759.0</td>\n",
              "      <td>1724.0</td>\n",
              "      <td>685.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>369.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1870</th>\n",
              "      <td>-117.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2469.0</td>\n",
              "      <td>532.0</td>\n",
              "      <td>1068.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>122.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>-117.2</td>\n",
              "      <td>32.8</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1588.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>683.0</td>\n",
              "      <td>301.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>332.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17000 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "14948     -122.2      37.5                29.0       1617.0           235.0   \n",
              "6812      -118.3      34.1                26.0       2107.0           757.0   \n",
              "14564     -122.2      37.9                32.0       1779.0           241.0   \n",
              "9273      -119.1      35.4                37.0       2044.0           394.0   \n",
              "7940      -118.4      34.3                38.0        858.0           203.0   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "6189      -118.2      34.1                 8.0       1204.0           552.0   \n",
              "6963      -118.3      34.0                44.0       1555.0           324.0   \n",
              "1799      -117.3      33.0                 9.0       4632.0           759.0   \n",
              "1870      -117.3      34.2                26.0       2469.0           532.0   \n",
              "1681      -117.2      32.8                33.0       1588.0           289.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "14948       758.0       246.0            7.8               469.9  \n",
              "6812       2660.0       740.0            2.3               282.3  \n",
              "14564       721.0       258.0            8.8               434.5  \n",
              "9273        894.0       359.0            2.9                82.8  \n",
              "7940       1250.0       204.0            2.9               137.9  \n",
              "...           ...         ...            ...                 ...  \n",
              "6189       1074.0       517.0            1.0                87.5  \n",
              "6963        931.0       265.0            1.5               105.8  \n",
              "1799       1724.0       685.0            6.4               369.8  \n",
              "1870       1068.0       501.0            2.0               122.1  \n",
              "1681        683.0       301.0            5.4               332.4  \n",
              "\n",
              "[17000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "HzzlSs3PtTmt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Examine the Data\n",
        "\n",
        "It's a good idea to get to know your data a little bit before you work with it.\n",
        "\n",
        "We'll print out a quick summary of a few useful statistics on each column: count of examples, mean, standard deviation, max, min, and various quantiles."
      ]
    },
    {
      "metadata": {
        "id": "gzb10yoVrydW",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "c1e069ed-82d2-48c8-d9b6-e91fdd47b950"
      },
      "cell_type": "code",
      "source": [
        "california_housing_dataframe.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-119.6</td>\n",
              "      <td>35.6</td>\n",
              "      <td>28.6</td>\n",
              "      <td>2643.7</td>\n",
              "      <td>539.4</td>\n",
              "      <td>1429.6</td>\n",
              "      <td>501.2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>207.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2179.9</td>\n",
              "      <td>421.5</td>\n",
              "      <td>1147.9</td>\n",
              "      <td>384.5</td>\n",
              "      <td>1.9</td>\n",
              "      <td>116.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-124.3</td>\n",
              "      <td>32.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-121.8</td>\n",
              "      <td>33.9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1462.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>119.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-118.5</td>\n",
              "      <td>34.2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>1167.0</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>180.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.7</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3151.2</td>\n",
              "      <td>648.2</td>\n",
              "      <td>1721.0</td>\n",
              "      <td>605.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>265.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>42.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>37937.0</td>\n",
              "      <td>6445.0</td>\n",
              "      <td>35682.0</td>\n",
              "      <td>6082.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
              "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
              "std          2.0       2.1                12.6       2179.9           421.5   \n",
              "min       -124.3      32.5                 1.0          2.0             1.0   \n",
              "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
              "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
              "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
              "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "count     17000.0     17000.0        17000.0             17000.0  \n",
              "mean       1429.6       501.2            3.9               207.3  \n",
              "std        1147.9       384.5            1.9               116.0  \n",
              "min           3.0         1.0            0.5                15.0  \n",
              "25%         790.0       282.0            2.6               119.4  \n",
              "50%        1167.0       409.0            3.5               180.4  \n",
              "75%        1721.0       605.2            4.8               265.0  \n",
              "max       35682.0      6082.0           15.0               500.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Lr6wYl2bt2Ep",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Build the First Model\n",
        "\n",
        "In this exercise, we'll try to predict `median_house_value`, which will be our label (sometimes also called a target). We'll use `total_rooms` as our input feature.\n",
        "\n",
        "**NOTE:** Our data is at the city block level, so this feature represents the total number of rooms in that block.\n",
        "\n",
        "To train our model, we'll use the [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) interface provided by the TensorFlow [Estimator](https://www.tensorflow.org/get_started/estimator) API. This API takes care of a lot of the low-level model plumbing, and exposes convenient methods for performing model training, evaluation, and inference."
      ]
    },
    {
      "metadata": {
        "id": "0cpcsieFhsNI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Step 1: Define Features and Configure Feature Columns"
      ]
    },
    {
      "metadata": {
        "id": "EL8-9d4ZJNR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to import our training data into TensorFlow, we need to specify what type of data each feature contains. There are two main types of data we'll use in this and future exercises:\n",
        "\n",
        "* **Categorical Data**: Data that is textual. In this exercise, our housing data set does not contain any categorical features, but examples you might see would be the home style, the words in a real-estate ad.\n",
        "\n",
        "* **Numerical Data**: Data that is a number (integer or float) and that you want to treat as a number. As we will discuss more later sometimes you might want to treat numerical data (e.g., a postal code) as if it were categorical.\n",
        "\n",
        "In TensorFlow, we indicate a feature's data type using a construct called a **feature column**. Feature columns store only a description of the feature data; they do not contain the feature data itself.\n",
        "\n",
        "To start, we're going to use just one numeric input feature, `total_rooms`. The following code pulls the `total_rooms` data from our `california_housing_dataframe` and defines the feature column using `numeric_column`, which specifies its data is numeric:"
      ]
    },
    {
      "metadata": {
        "id": "rhEbFCZ86cDZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the input feature: total_rooms.\n",
        "my_feature = california_housing_dataframe[[\"total_rooms\"]]\n",
        "\n",
        "# Configure a numeric feature column for total_rooms.\n",
        "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_3S8teX7Rd2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The shape of our `total_rooms` data is a one-dimensional array (a list of the total number of rooms for each block). This is the default shape for `numeric_column`, so we don't have to pass it as an argument."
      ]
    },
    {
      "metadata": {
        "id": "UMl3qrU5MGV6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Step 2: Define the Target"
      ]
    },
    {
      "metadata": {
        "id": "cw4nrfcB7kyk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we'll define our target, which is `median_house_value`. Again, we can pull it from our `california_housing_dataframe`:"
      ]
    },
    {
      "metadata": {
        "id": "l1NvvNkH8Kbt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the label.\n",
        "targets = california_housing_dataframe[\"median_house_value\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4M-rTFHL2UkA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Step 3: Configure the LinearRegressor"
      ]
    },
    {
      "metadata": {
        "id": "fUfGQUNp7jdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we'll configure a linear regression model using LinearRegressor. We'll train this model using the `GradientDescentOptimizer`, which implements Mini-Batch Stochastic Gradient Descent (SGD). The `learning_rate` argument controls the size of the gradient step.\n",
        "\n",
        "**NOTE:** To be safe, we also apply [gradient clipping](https://developers.google.com/machine-learning/glossary/#gradient_clipping) to our optimizer via `clip_gradients_by_norm`. Gradient clipping ensures the magnitude of the gradients do not become too large during training, which can cause gradient descent to fail. "
      ]
    },
    {
      "metadata": {
        "id": "ubhtW-NGU802",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "4adc84b7-3fdb-41bb-812b-cd6c3cbabeb8"
      },
      "cell_type": "code",
      "source": [
        "# Use gradient descent as the optimizer for training the model.\n",
        "my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "# Configure the linear regression model with our feature columns and optimizer.\n",
        "# Set a learning rate of 0.0000001 for Gradient Descent.\n",
        "linear_regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=feature_columns,\n",
        "    optimizer=my_optimizer\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-0IztwdK2f3F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Step 4: Define the Input Function"
      ]
    },
    {
      "metadata": {
        "id": "S5M5j6xSCHxx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To import our California housing data into our `LinearRegressor`, we need to define an input function, which instructs TensorFlow how to preprocess\n",
        "the data, as well as how to batch, shuffle, and repeat it during model training.\n",
        "\n",
        "First, we'll convert our *pandas* feature data into a dict of NumPy arrays. We can then use the TensorFlow [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) to construct a dataset object from our data, and then break\n",
        "our data into batches of `batch_size`, to be repeated for the specified number of epochs (num_epochs). \n",
        "\n",
        "**NOTE:** When the default value of `num_epochs=None` is passed to `repeat()`, the input data will be repeated indefinitely.\n",
        "\n",
        "Next, if `shuffle` is set to `True`, we'll shuffle the data so that it's passed to the model randomly during training. The `buffer_size` argument specifies\n",
        "the size of the dataset from which `shuffle` will randomly sample.\n",
        "\n",
        "Finally, our input function constructs an iterator for the dataset and returns the next batch of data to the LinearRegressor."
      ]
    },
    {
      "metadata": {
        "id": "RKZ9zNcHJtwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a linear regression model of one feature.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "  \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(buffer_size=10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwa6UeA1V5F_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**NOTE:** We'll continue to use this same input function in later exercises. For more\n",
        "detailed documentation of input functions and the `Dataset` API, see the [TensorFlow Programmer's Guide](https://www.tensorflow.org/programmers_guide/datasets)."
      ]
    },
    {
      "metadata": {
        "id": "4YS50CQb2ooO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Step 5: Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "yP92XkzhU803",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now call `train()` on our `linear_regressor` to train the model. We'll wrap `my_input_fn` in a `lambda`\n",
        "so we can pass in `my_feature` and `target` as arguments (see this [TensorFlow input function tutorial](https://www.tensorflow.org/get_started/input_fn#passing_input_fn_data_to_your_model) for more details), and to start, we'll\n",
        "train for 100 steps."
      ]
    },
    {
      "metadata": {
        "id": "5M-Kt6w8U803",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_ = linear_regressor.train(\n",
        "    input_fn = lambda:my_input_fn(my_feature, targets),\n",
        "    steps=100\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Nwxqxlx2sOv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Step 6: Evaluate the Model"
      ]
    },
    {
      "metadata": {
        "id": "KoDaF2dlJQG5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's make predictions on that training data, to see how well our model fit it during training.\n",
        "\n",
        "**NOTE:** Training error measures how well your model fits the training data, but it **_does not_** measure how well your model **_generalizes to new data_**. In later exercises, you'll explore how to split your data to evaluate your model's ability to generalize.\n"
      ]
    },
    {
      "metadata": {
        "id": "pDIxp6vcU809",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "beeccc9d-eec0-4339-c42c-e5de4b97918f"
      },
      "cell_type": "code",
      "source": [
        "# Create an input function for predictions.\n",
        "# Note: Since we're making just one prediction for each example, we don't \n",
        "# need to repeat or shuffle the data here.\n",
        "prediction_input_fn =lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)\n",
        "\n",
        "# Call predict() on the linear_regressor to make predictions.\n",
        "predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
        "\n",
        "# Format predictions as a NumPy array, so we can calculate error metrics.\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "# Print Mean Squared Error and Root Mean Squared Error.\n",
        "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
        "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
        "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
        "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Squared Error (on training data): 56367.025\n",
            "Root Mean Squared Error (on training data): 237.417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AKWstXXPzOVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Is this a good model? How would you judge how large this error is?\n",
        "\n",
        "Mean Squared Error (MSE) can be hard to interpret, so we often look at Root Mean Squared Error (RMSE)\n",
        "instead.  A nice property of RMSE is that it can be interpreted on the same scale as the original targets.\n",
        "\n",
        "Let's compare the RMSE to the difference of the min and max of our targets:"
      ]
    },
    {
      "metadata": {
        "id": "7UwqGbbxP53O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "9a90f1b9-bbcb-4749-c38f-90b29642af87"
      },
      "cell_type": "code",
      "source": [
        "min_house_value = california_housing_dataframe[\"median_house_value\"].min()\n",
        "max_house_value = california_housing_dataframe[\"median_house_value\"].max()\n",
        "min_max_difference = max_house_value - min_house_value\n",
        "\n",
        "print(\"Min. Median House Value: %0.3f\" % min_house_value)\n",
        "print(\"Max. Median House Value: %0.3f\" % max_house_value)\n",
        "print(\"Difference between Min. and Max.: %0.3f\" % min_max_difference)\n",
        "print(\"Root Mean Squared Error: %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min. Median House Value: 14.999\n",
            "Max. Median House Value: 500.001\n",
            "Difference between Min. and Max.: 485.002\n",
            "Root Mean Squared Error: 237.417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JigJr0C7Pzit",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our error spans nearly half the range of the target values. Can we do better?\n",
        "\n",
        "This is the question that nags at every model developer. Let's develop some basic strategies to reduce model error.\n",
        "\n",
        "The first thing we can do is take a look at how well our predictions match our targets, in terms of overall summary statistics."
      ]
    },
    {
      "metadata": {
        "id": "941nclxbzqGH",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5e25b043-80f9-4176-e5e0-b7062f3eabaf"
      },
      "cell_type": "code",
      "source": [
        "calibration_data = pd.DataFrame()\n",
        "calibration_data[\"predictions\"] = pd.Series(predictions)\n",
        "calibration_data[\"targets\"] = pd.Series(targets)\n",
        "calibration_data.describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.1</td>\n",
              "      <td>207.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.1</td>\n",
              "      <td>116.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.1</td>\n",
              "      <td>119.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.1</td>\n",
              "      <td>180.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.2</td>\n",
              "      <td>265.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.9</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       predictions  targets\n",
              "count      17000.0  17000.0\n",
              "mean           0.1    207.3\n",
              "std            0.1    116.0\n",
              "min            0.0     15.0\n",
              "25%            0.1    119.4\n",
              "50%            0.1    180.4\n",
              "75%            0.2    265.0\n",
              "max            1.9    500.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "E2-bf8Hq36y8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Okay, maybe this information is helpful. How does the mean value compare to the model's RMSE? How about the various quantiles?\n",
        "\n",
        "We can also visualize the data and the line we've learned.  Recall that linear regression on a single feature can be drawn as a line mapping input *x* to output *y*.\n",
        "\n",
        "First, we'll get a uniform random sample of the data so we can make a readable scatter plot."
      ]
    },
    {
      "metadata": {
        "id": "SGRIi3mAU81H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample = california_housing_dataframe.sample(n=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-JwuJBKU81J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we'll plot the line we've learned, drawing from the model's bias term and feature weight, together with the scatter plot. The line will show up red."
      ]
    },
    {
      "metadata": {
        "id": "7G12E76-339G",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "b0e3841e-7549-414f-cf05-ea7c37afa0c2"
      },
      "cell_type": "code",
      "source": [
        "# Get the min and max total_rooms values.\n",
        "x_0 = sample[\"total_rooms\"].min()\n",
        "x_1 = sample[\"total_rooms\"].max()\n",
        "\n",
        "# Retrieve the final weight and bias generated during training.\n",
        "weight = linear_regressor.get_variable_value('linear/linear_model/total_rooms/weights')[0]\n",
        "bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
        "\n",
        "# Get the predicted median_house_values for the min and max total_rooms values.\n",
        "y_0 = weight * x_0 + bias \n",
        "y_1 = weight * x_1 + bias\n",
        "\n",
        "# Plot our regression line from (x_0, y_0) to (x_1, y_1).\n",
        "plt.plot([x_0, x_1], [y_0, y_1], c='r')\n",
        "\n",
        "# Label the graph axes.\n",
        "plt.ylabel(\"median_house_value\")\n",
        "plt.xlabel(\"total_rooms\")\n",
        "\n",
        "# Plot a scatter plot from our data sample.\n",
        "plt.scatter(sample[\"total_rooms\"], sample[\"median_house_value\"])\n",
        "\n",
        "# Display graph.\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAFYCAYAAAC2307rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "t0lRt4USU81L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This initial line looks way off.  See if you can look back at the summary stats and see the same information encoded there.\n",
        "\n",
        "Together, these initial sanity checks suggest we may be able to find a much better line."
      ]
    },
    {
      "metadata": {
        "id": "AZWF67uv0HTG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tweak the Model Hyperparameters\n",
        "For this exercise, we've put all the above code in a single function for convenience. You can call the function with different parameters to see the effect.\n",
        "\n",
        "In this function, we'll proceed in 10 evenly divided periods so that we can observe the model improvement at each period.\n",
        "\n",
        "For each period, we'll compute and graph training loss.  This may help you judge when a model is converged, or if it needs more iterations.\n",
        "\n",
        "We'll also plot the feature weight and bias term values learned by the model over time.  This is another way to see how things converge."
      ]
    },
    {
      "metadata": {
        "id": "wgSMeD5UU81N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(learning_rate, steps, batch_size, input_feature=\"total_rooms\"):\n",
        "  \"\"\"Trains a linear regression model of one feature.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    input_feature: A `string` specifying a column from `california_housing_dataframe`\n",
        "      to use as input feature.\n",
        "  \"\"\"\n",
        "  \n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "\n",
        "  my_feature = input_feature\n",
        "  my_feature_data = california_housing_dataframe[[my_feature]]\n",
        "  my_label = \"median_house_value\"\n",
        "  targets = california_housing_dataframe[my_label]\n",
        "\n",
        "  # Create feature columns.\n",
        "  feature_columns = [tf.feature_column.numeric_column(my_feature)]\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda:my_input_fn(my_feature_data, targets, batch_size=batch_size)\n",
        "  prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
        "  \n",
        "  # Create a linear regressor object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_regressor = tf.estimator.LinearRegressor(\n",
        "      feature_columns=feature_columns,\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "\n",
        "  # Set up to plot the state of our model's line each period.\n",
        "  plt.figure(figsize=(15, 6))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title(\"Learned Line by Period\")\n",
        "  plt.ylabel(my_label)\n",
        "  plt.xlabel(my_feature)\n",
        "  sample = california_housing_dataframe.sample(n=300)\n",
        "  plt.scatter(sample[my_feature], sample[my_label])\n",
        "  colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  root_mean_squared_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.\n",
        "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
        "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "    \n",
        "    # Compute loss.\n",
        "    root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(predictions, targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, root_mean_squared_error))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    root_mean_squared_errors.append(root_mean_squared_error)\n",
        "    # Finally, track the weights and biases over time.\n",
        "    # Apply some math to ensure that the data and line are plotted neatly.\n",
        "    y_extents = np.array([0, sample[my_label].max()])\n",
        "    \n",
        "    weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0]\n",
        "    bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
        "\n",
        "    x_extents = (y_extents - bias) / weight\n",
        "    x_extents = np.maximum(np.minimum(x_extents,\n",
        "                                      sample[my_feature].max()),\n",
        "                           sample[my_feature].min())\n",
        "    y_extents = weight * x_extents + bias\n",
        "    plt.plot(x_extents, y_extents, color=colors[period]) \n",
        "  print(\"Model training finished.\")\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.xlabel('Periods')\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(root_mean_squared_errors)\n",
        "\n",
        "  # Output a table with calibration data.\n",
        "  calibration_data = pd.DataFrame()\n",
        "  calibration_data[\"predictions\"] = pd.Series(predictions)\n",
        "  calibration_data[\"targets\"] = pd.Series(targets)\n",
        "  display.display(calibration_data.describe())\n",
        "\n",
        "  print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kg8A4ArBU81Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Task 1:  Achieve an RMSE of 180 or Below\n",
        "\n",
        "Tweak the model hyperparameters to improve loss and better match the target distribution.\n",
        "If, after 5 minutes or so, you're having trouble beating a RMSE of 180, check the solution for a possible combination."
      ]
    },
    {
      "metadata": {
        "id": "UzoZUSdLIolF",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_model(\n",
        "    learning_rate=0.00001,\n",
        "    steps=100,\n",
        "    batch_size=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajVM7rkoYXeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Solution\n",
        "\n",
        "Click below for one possible solution."
      ]
    },
    {
      "metadata": {
        "id": "T3zmldDwYy5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4411
        },
        "outputId": "f305bdcb-1db6-4bc7-82db-5f8ed4ffb9cb"
      },
      "cell_type": "code",
      "source": [
        "train_model(\n",
        "    learning_rate=0.00002,\n",
        "    steps=500,\n",
        "    batch_size=5\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 225.63\n",
            "  period 01 : 214.42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-745905fcb939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-18-08b005cc5bf7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(learning_rate, steps, batch_size, input_feature)\u001b[0m\n\u001b[1;32m     53\u001b[0m     linear_regressor.train(\n\u001b[1;32m     54\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Take a break and compute predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1152\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1154\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1155\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1185\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m           sparse_combiner=sparse_combiner)\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     super(LinearRegressor, self).__init__(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_linear_model_fn\u001b[0;34m(features, labels, mode, head, feature_columns, optimizer, partitioner, config, sparse_combiner)\u001b[0m\n\u001b[1;32m    527\u001b[0m           \u001b[0msparse_combiner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_combiner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m           )\n\u001b[0;32m--> 529\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m       optimizer = optimizers.get_optimizer_instance(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36mlinear_logit_fn\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     summary.scalar('fraction_of_zero_weights',\n\u001b[0;32m--> 376\u001b[0;31m                    _compute_fraction_of_zero(variables))\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_compute_fraction_of_zero\u001b[0;34m(variables)\u001b[0m\n\u001b[1;32m    297\u001b[0m               \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_fraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m               name='zero_count')\n\u001b[0;32m--> 299\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m       ])\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    297\u001b[0m               \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_fraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m               name='zero_count')\n\u001b[0;32m--> 299\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m       ])\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   2106\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m       \u001b[0mcontext_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2108\u001b[0;31m       \u001b[0morig_res_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2109\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0morig_res_f\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"false_fn must have a return value.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1939\u001b[0m     \u001b[0;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1941\u001b[0;31m     \u001b[0moriginal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1942\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1943\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_summaries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_summaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    295\u001b[0m               \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m               \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m               \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_fraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m               name='zero_count')\n\u001b[1;32m    299\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mto_float\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcast\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m   \"\"\"\n\u001b[0;32m--> 672\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1895\u001b[0m   \u001b[0mTruncate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Truncate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 1897\u001b[0;31m         \"Cast\", x=x, DstT=DstT, Truncate=Truncate, name=name)\n\u001b[0m\u001b[1;32m   1898\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reconstruct_sequence_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddOp\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mAddOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_AddOpInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_AddOpInternal\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   1872\u001b[0m           \u001b[0mreal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m           \u001b[0mreal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreal_x\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m           \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddValue\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m   1818\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_external_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1820\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SwitchRefOrTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outer_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outer_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddInnerOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_SwitchRefOrTensor\u001b[0;34m(data, pred, name)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mref_switch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mswitch\u001b[0;34m(data, pred, dtype, name)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_control_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_control_flow_ops.py\u001b[0m in \u001b[0;36mswitch\u001b[0;34m(data, pred, name)\u001b[0m\n\u001b[1;32m    861\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 863\u001b[0;31m         \"Switch\", data=data, pred=pred, name=name)\n\u001b[0m\u001b[1;32m    864\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m           \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0mbase_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAGCCAYAAACB/JaMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6IVU4l8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "M8H0_D4vYa49",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is just one possible configuration; there may be other combinations of settings that also give good results. Note that in general, this exercise isn't about finding the *one best* setting, but to help build your intutions about how tweaking the model configuration affects prediction quality."
      ]
    },
    {
      "metadata": {
        "id": "zoD41nAmVUxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Is There a Standard Heuristic for Model Tuning?\n"
      ]
    },
    {
      "metadata": {
        "id": "QU5sLyYTqzqL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a commonly asked question. The short answer is that the effects of different hyperparameters are data dependent. So there are no hard-and-fast rules; you'll need to test on your data.\n",
        "\n",
        "That said, here are a few rules of thumb that may help guide you:\n",
        "\n",
        " * Training error should steadily decrease, steeply at first, and should eventually plateau as training converges.\n",
        " * If the training has not converged, try running it for longer.\n",
        " * If the training error decreases too slowly, increasing the learning rate may help it decrease faster.\n",
        "   * But sometimes the exact opposite may happen if the learning rate is too high.\n",
        " * If the training error varies wildly, try decreasing the learning rate.\n",
        "   * Lower learning rate plus larger number of steps or larger batch size is often a good combination.\n",
        " * Very small batch sizes can also cause instability.  First try larger values like 100 or 1000, and decrease until you see degradation.\n",
        "\n",
        "Again, never go strictly by these rules of thumb, because the effects are data dependent.  Always experiment and verify."
      ]
    },
    {
      "metadata": {
        "id": "GpV-uF_cBCBU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Task 2: Try a Different Feature\n",
        "\n",
        "See if you can do any better by replacing the `total_rooms` feature with the `population` feature.\n",
        "\n",
        "Don't take more than 5 minutes on this portion."
      ]
    },
    {
      "metadata": {
        "id": "YMyOxzb0ZlAH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ci1ISxxrZ7v0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Solution\n",
        "\n",
        "Click below for one possible solution."
      ]
    },
    {
      "metadata": {
        "id": "SjdQQCduZ7BV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_model(\n",
        "    learning_rate=0.00002,\n",
        "    steps=1000,\n",
        "    batch_size=5,\n",
        "    input_feature=\"population\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DskmJEsu8xdX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Enable TPU Support in Colab"
      ]
    },
    {
      "metadata": {
        "id": "rrWQ83Cd81dN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![TPU](https://user-images.githubusercontent.com/58792/53053297-d14f2400-3455-11e9-836d-3857de1f4337.png)"
      ]
    },
    {
      "metadata": {
        "id": "QDDm6TsK34PC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras"
      ]
    },
    {
      "metadata": {
        "id": "ItXfxkxvosLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text classification with movie reviews (Project)"
      ]
    },
    {
      "metadata": {
        "id": "hKY4XMc9o8iB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Modified based on this tutorial: * https://research.google.com/seedbank/seed/classify_movie_reviews_using_tfkeras\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/basic_text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "Eg62Pmz3o83v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "This notebook classifies movie reviews as *positive* or *negative* using the text of the review. This is an example of *binary*â€”or two-classâ€”classification, an important and widely applicable kind of machine learning problem. \n",
        "\n",
        "We'll use the [IMDB dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) that contains the text of 50,000 movie reviews from the [Internet Movie Database](https://www.imdb.com/). These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are *balanced*, meaning they contain an equal number of positive and negative reviews. \n",
        "\n",
        "This notebook uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow. For a more advanced text classification tutorial using `tf.keras`, see the [MLCC Text Classification Guide](https://developers.google.com/machine-learning/guides/text-classification/)."
      ]
    },
    {
      "metadata": {
        "id": "2ew7HTbPpCJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0eb06a23-38b4-4d48-b0d7-c5bd58ece20a"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zZ8c25ug_FTf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Ingest"
      ]
    },
    {
      "metadata": {
        "id": "iAsKG535pHep",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Download the IMDB dataset\n",
        "\n",
        "The IMDB dataset comes packaged with TensorFlow. It has already been preprocessed such that the reviews (sequences of words) have been converted to sequences of integers, where each integer represents a specific word in a dictionary.\n",
        "\n",
        "The following code downloads the IMDB dataset to your machine (or uses a cached copy if you've already downloaded it):"
      ]
    },
    {
      "metadata": {
        "id": "zXXx5Oc3pOmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a6afd2d-2100-4903-b672-638331e84741"
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "odr-KlzO-lkL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The argument `num_words=10000` keeps the top 10,000 most frequently occurring words in the training data. The rare words are discarded to keep the size of the data manageable."
      ]
    },
    {
      "metadata": {
        "id": "l50X3GfjpU4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Explore the data (EDA)\n",
        "\n",
        "Let's take a moment to understand the format of the data. The dataset comes preprocessed: each example is an array of integers representing the words of the movie review. Each label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review."
      ]
    },
    {
      "metadata": {
        "id": "y8qCnve_-lkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4efab3c9-795c-46a1-e6ec-7db49afde06d"
      },
      "cell_type": "code",
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RnKvHWW4-lkW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The text of reviews have been converted to integers, where each integer represents a specific word in a dictionary. Here's what the first review looks like:"
      ]
    },
    {
      "metadata": {
        "id": "QtTS4kpEpjbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "da10cc25-387f-4986-ab03-142e366e9d5f"
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hIE4l_72x7DP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Movie reviews may be different lengths. The below code shows the number of words in the first and second reviews. Since inputs to a neural network must be the same length, we'll need to resolve this later."
      ]
    },
    {
      "metadata": {
        "id": "X-6Ii9Pfx6Nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44001fb8-6e71-411d-fa31-89cb5ea99c50"
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "4wJg2FiYpuoX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Convert the integers back to words\n",
        "\n",
        "It may be useful to know how to convert integers back to text. Here, we'll create a helper function to query a dictionary object that contains the integer to string mapping:"
      ]
    },
    {
      "metadata": {
        "id": "tr5s_1alpzop",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "06a61e50-abad-4c3c-9808-d3acee0ff89b"
      },
      "cell_type": "code",
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U3CNRvEZVppl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can use the `decode_review` function to display the text for the first review:"
      ]
    },
    {
      "metadata": {
        "id": "s_OqxmH6-lkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "615733f4-3483-4ffd-daa5-0aa96449a5e4"
      },
      "cell_type": "code",
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "lFP_XKVRp4_S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Prepare the data\n",
        "\n",
        "The reviewsâ€”the arrays of integersâ€”must be converted to tensors before fed into the neural network. This conversion can be done a couple of ways:\n",
        "\n",
        "* Convert the arrays into vectors of 0s and 1s indicating word occurrence, similar to a one-hot encoding. For example, the sequence  [3, 5] would become a 10,000-dimensional vector that is all zeros except for indices 3 and 5, which are ones. Then, make this the first layer in our networkâ€”a Dense layerâ€”that can handle floating point vector data. This approach is memory intensive, though, requiring a `num_words * num_reviews` size matrix.\n",
        "\n",
        "* Alternatively, we can pad the arrays so they all have the same length, then create an integer tensor of shape `max_length * num_reviews`. We can use an embedding layer capable of handling this shape as the first layer in our network.\n",
        "\n",
        "In this tutorial, we will use the second approach. \n",
        "\n",
        "Since the movie reviews must be the same length, we will use the [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) function to standardize the lengths:"
      ]
    },
    {
      "metadata": {
        "id": "2jQv-omsHurp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VO5MBpyQdipD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's look at the length of the examples now:"
      ]
    },
    {
      "metadata": {
        "id": "USSSBnkE-lky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "674cf482-21a0-4cba-a715-c730639452cc"
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "QJoxZGyfjT5V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And inspect the (now padded) first review:"
      ]
    },
    {
      "metadata": {
        "id": "TG8X9cqi-lk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "bd7e5199-e6c5-4623-c4ae-8307650b4e3f"
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LLC02j2g-llC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Modeling\n",
        "\n",
        "The neural network is created by stacking layersâ€”this requires two main architectural decisions:\n",
        "\n",
        "* How many layers to use in the model?\n",
        "* How many *hidden units* to use for each layer?\n",
        "\n",
        "In this example, the input data consists of an array of word-indices. The labels to predict are either 0 or 1. Let's build a model for this problem:"
      ]
    },
    {
      "metadata": {
        "id": "xpKOoWgu-llD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "bb3df190-6c9e-4602-aad5-96e1212d728a"
      },
      "cell_type": "code",
      "source": [
        "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6PbKQ6mucuKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The layers are stacked sequentially to build the classifier:\n",
        "\n",
        "1. The first layer is an `Embedding` layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: `(batch, sequence, embedding)`.\n",
        "2. Next, a `GlobalAveragePooling1D` layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
        "3. This fixed-length output vector is piped through a fully-connected (`Dense`) layer with 16 hidden units.\n",
        "4. The last layer is densely connected with a single output node. Using the `sigmoid` activation function, this value is a float between 0 and 1, representing a probability, or confidence level."
      ]
    },
    {
      "metadata": {
        "id": "Bn9ukmAb_pKE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Hidden units"
      ]
    },
    {
      "metadata": {
        "id": "0XMwnDOp-llH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The above model has two intermediate or \"hidden\" layers, between the input and output. The number of outputs (units, nodes, or neurons) is the dimension of the representational space for the layer. In other words, the amount of freedom the network is allowed when learning an internal representation.\n",
        "\n",
        "If a model has more hidden units (a higher-dimensional representation space), and/or more layers, then the network can learn more complex representations. However, it makes the network more computationally expensive and may lead to learning unwanted patternsâ€”patterns that improve performance on training data but not on the test data. This is called *overfitting*, and we'll explore it later."
      ]
    },
    {
      "metadata": {
        "id": "L4EqVWg4-llM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Loss function and optimizer\n",
        "\n",
        "A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), we'll use the `binary_crossentropy` loss function. \n",
        "\n",
        "This isn't the only choice for a loss function, you could, for instance, choose `mean_squared_error`. But, generally, `binary_crossentropy` is better for dealing with probabilitiesâ€”it measures the \"distance\" between probability distributions, or in our case, between the ground-truth distribution and the predictions.\n",
        "\n",
        "Later, when we are exploring regression problems (say, to predict the price of a house), we will see how to use another loss function called mean squared error.\n",
        "\n",
        "Now, configure the model to use an optimizer and a loss function:"
      ]
    },
    {
      "metadata": {
        "id": "Mr0GP-cQ-llN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCWYwkug-llQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Create a validation set\n",
        "\n",
        "When training, we want to check the accuracy of the model on data it hasn't seen before. Create a *validation set* by setting apart 10,000 examples from the original training data. (Why not use the testing set now? Our goal is to develop and tune our model using only the training data, then use the test data just once to evaluate our accuracy)."
      ]
    },
    {
      "metadata": {
        "id": "-NpcXY9--llS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35jv_fzP-llU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Train the model\n",
        "\n",
        "Train the model for 40 epochs in mini-batches of 512 samples. This is 40 iterations over all samples in the `x_train` and `y_train` tensors. While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set:"
      ]
    },
    {
      "metadata": {
        "id": "tXSGrjWZ-llW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1426
        },
        "outputId": "283dd599-0228-44be-a721-fa99fc6c91a8"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 38us/sample - loss: 0.6915 - acc: 0.5184 - val_loss: 0.6893 - val_acc: 0.5228\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.6846 - acc: 0.6173 - val_loss: 0.6797 - val_acc: 0.6627\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.6694 - acc: 0.7195 - val_loss: 0.6606 - val_acc: 0.7439\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.6425 - acc: 0.7570 - val_loss: 0.6306 - val_acc: 0.7719\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.6051 - acc: 0.7929 - val_loss: 0.5927 - val_acc: 0.7922\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.5600 - acc: 0.8187 - val_loss: 0.5506 - val_acc: 0.8065\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.5119 - acc: 0.8357 - val_loss: 0.5061 - val_acc: 0.8257\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.4652 - acc: 0.8538 - val_loss: 0.4664 - val_acc: 0.8391\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.4229 - acc: 0.8667 - val_loss: 0.4315 - val_acc: 0.8483\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.3859 - acc: 0.8769 - val_loss: 0.4032 - val_acc: 0.8530\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.3549 - acc: 0.8849 - val_loss: 0.3797 - val_acc: 0.8612\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.3286 - acc: 0.8928 - val_loss: 0.3618 - val_acc: 0.8643\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.3070 - acc: 0.8976 - val_loss: 0.3459 - val_acc: 0.8698\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.2875 - acc: 0.9027 - val_loss: 0.3342 - val_acc: 0.8735\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.2711 - acc: 0.9083 - val_loss: 0.3243 - val_acc: 0.8745\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.2562 - acc: 0.9134 - val_loss: 0.3162 - val_acc: 0.8755\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.2425 - acc: 0.9176 - val_loss: 0.3094 - val_acc: 0.8796\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.2303 - acc: 0.9223 - val_loss: 0.3036 - val_acc: 0.8820\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.2193 - acc: 0.9245 - val_loss: 0.2988 - val_acc: 0.8816\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.2094 - acc: 0.9287 - val_loss: 0.2955 - val_acc: 0.8821\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.1992 - acc: 0.9339 - val_loss: 0.2927 - val_acc: 0.8834\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 0s 22us/sample - loss: 0.1908 - acc: 0.9367 - val_loss: 0.2901 - val_acc: 0.8843\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1822 - acc: 0.9409 - val_loss: 0.2892 - val_acc: 0.8840\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.1748 - acc: 0.9441 - val_loss: 0.2879 - val_acc: 0.8851\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.1672 - acc: 0.9475 - val_loss: 0.2862 - val_acc: 0.8860\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1605 - acc: 0.9498 - val_loss: 0.2870 - val_acc: 0.8838\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.1540 - acc: 0.9525 - val_loss: 0.2864 - val_acc: 0.8850\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.1479 - acc: 0.9551 - val_loss: 0.2872 - val_acc: 0.8852\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1425 - acc: 0.9581 - val_loss: 0.2884 - val_acc: 0.8852\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.1368 - acc: 0.9593 - val_loss: 0.2880 - val_acc: 0.8860\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.1311 - acc: 0.9616 - val_loss: 0.2890 - val_acc: 0.8863\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.1260 - acc: 0.9645 - val_loss: 0.2905 - val_acc: 0.8856\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.1210 - acc: 0.9665 - val_loss: 0.2928 - val_acc: 0.8848\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 0s 22us/sample - loss: 0.1166 - acc: 0.9675 - val_loss: 0.2950 - val_acc: 0.8848\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1125 - acc: 0.9683 - val_loss: 0.2974 - val_acc: 0.8852\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.1081 - acc: 0.9706 - val_loss: 0.2991 - val_acc: 0.8839\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 0s 22us/sample - loss: 0.1037 - acc: 0.9720 - val_loss: 0.3018 - val_acc: 0.8835\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.0998 - acc: 0.9735 - val_loss: 0.3053 - val_acc: 0.8822\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.0967 - acc: 0.9745 - val_loss: 0.3090 - val_acc: 0.8817\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.0926 - acc: 0.9765 - val_loss: 0.3118 - val_acc: 0.8829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9EEGuDVuzb5r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Evaluate the model\n",
        "\n",
        "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "metadata": {
        "id": "zOMKywn4zReN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b0d90f45-34b0-4b0e-ddd4-e55c4b5e825f"
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 2s 62us/sample - loss: 0.3331 - acc: 0.8706\n",
            "[0.3330800845146179, 0.87064]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z1iEXVTR0Z2t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This fairly naive approach achieves an accuracy of about 87%. With more advanced approaches, the model should get closer to 95%."
      ]
    },
    {
      "metadata": {
        "id": "5KggXVeL-llZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Create a graph of accuracy and loss over time\n",
        "\n",
        "`model.fit()` returns a `History` object that contains a dictionary with everything that happened during training:"
      ]
    },
    {
      "metadata": {
        "id": "VcvSXvhp-llb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d54d9d02-5fb4-4aec-f28f-37312751a82e"
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "nRKsqL40-lle",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are four entries: one for each monitored metric during training and validation. We can use these to plot the training and validation loss for comparison, as well as the training and validation accuracy:"
      ]
    },
    {
      "metadata": {
        "id": "nGoYf2Js-lle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "477547dc-4aee-4b53-eeac-2878610c5db3"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6hXx-xOv-llh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "5451608a-7791-443e-c13a-c5885a30f810"
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xlc1HXix/HXHIByqIDgnZqJiq6p\nlZurRR5492upbbMsKy0tM7U0UzfTar1KW7XTtNpSM61gOzbFu9M0tdxUzHJXxRsUDy5hjt8fI6PI\nAIMyMMO8n4+HD+b7nevzmS/yns/n+/l8vga73W5HREREfIaxsgsgIiIiZaPwFhER8TEKbxERER+j\n8BYREfExCm8REREfo/AWERHxMQpvqTImT55M79696d27N61bt6Zr167O7czMzDK9Vu/evUlPTy/x\nMbNnz2bp0qVXUuRy98ADD5CYmFgur9WiRQuOHj3K6tWrmTBhwhW93/Lly5233flsRaRk5sougEh5\nee6555y3u3Xrxosvvsj1119/Wa+1cuXKUh8zZsyYy3ptXxMfH098fPxlPz8tLY2FCxfy17/+FXDv\nsxWRkqnlLX7jvvvu4x//+Ad9+vRh27ZtpKenM2TIEHr37k23bt149913nY8taHVu2rSJu+66i9mz\nZ9OnTx+6devG5s2bARg/fjyvv/464Piy8OGHH/KXv/yFLl26MGPGDOdrvfnmm3Tq1Ik77riDJUuW\n0K1bN5fl++ijj+jTpw89e/Zk4MCBHDp0CIDExERGjhzJxIkT6dWrF3379uW3334DIDU1lTvvvJMe\nPXowZswYrFZrkdf96quvuPXWWwvtu+222/j6669L/AwKJCYm8sADD5T6fmvXruXWW2+lV69e3H77\n7aSkpAAwYMAADh8+TO/evcnLy3N+tgDvv/8+ffv2pXfv3jz66KOcPHnS+dnOmzePBx98kK5du/Lg\ngw+Sk5NTpGw5OTmMHj2aXr160a1bN2bOnOm8LzU1lYEDBxIfH88dd9zBzp07S9zfrVs3tmzZ4nx+\nwfbBgwfp0qUL06ZN49577y2xrgBvvfUW3bt3p1evXkyfPh2r1Urnzp355ZdfnI9ZvHgxw4cPL1If\nEXcpvMWv7Nixg3//+9906NCBN954g4YNG7Jy5Uree+89Zs+ezZEjR4o8Z9euXVx77bWsWLGCe+65\nhzfeeMPla//4448sW7aMTz75hMWLF3P06FF+++03Fi5cyKeffsoHH3xQbKvzxIkTPP/887z77rus\nWrWKq666yvnFAODrr7/mnnvuITk5mT/+8Y+89957AMyaNYtOnTqxZs0a7r//frZt21bktTt16sTR\no0dJTU0FHOF19OhR/vSnP7n9GRQo7v0sFgvjx4/nhRdeIDk5uVCQTps2jXr16rFy5UoCAwOdr/Xz\nzz/z9ttvs2jRIlauXEn9+vWZPXu28/6VK1fyj3/8g9WrV3Py5ElWr15dpDxLly4lKyuLlStXkpSU\nRGJiojOAJ02aRL9+/Vi9ejWPPvoo48aNK3F/SU6dOkWrVq1YvHhxiXXdsmULH3/8MZ9++imff/45\nW7duZdWqVfTp04cvvvjC+XqrV6+mX79+pb6vSHEU3uJX4uLiMBodv/bPPPMMkyZNAqBRo0ZERUVx\n8ODBIs8JCQmhR48eALRu3ZrDhw+7fO1bb70Vk8lEnTp1iIyM5MiRI/z444907NiR6OhogoKCuOOO\nO1w+NzIykq1bt1K3bl0Arr/+emfYAjRr1ow2bdoAEBsb6wzYLVu20LdvXwDatm3L1VdfXeS1AwMD\n6dq1K+vWrQNgzZo19OjRA7PZ7PZnUKC49zObzXz//fe0a9fOZfld2bBhA7169SIyMhKAO++8k+++\n+855f1xcHLVq1cJsNhMTE+PyS8XgwYN5/fXXMRgM1KxZk+bNm3Pw4EHOnTvHpk2b6N+/PwDdu3dn\n+fLlxe4vTX5+vvPUQUl1/frrr4mLiyM0NJTAwEAWLVpEz5496devH19++SU2m41Tp06xY8cOunbt\nWur7ihRH57zFr9SsWdN5+5dffnG2NI1GI2lpadhstiLPCQsLc942Go0uHwMQGhrqvG0ymbBarZw5\nc6bQe9apU8flc61WK/PmzWPdunVYrVaysrJo2rSpyzIUvDbA6dOnC71vjRo1XL5+r169eP/997n/\n/vtZs2aNs8vW3c+gQEnvt2jRIpKSksjLyyMvLw+DwVDs6wCcPHmS6OjoQq914sSJUut8sX379jFj\nxgz++9//YjQaOXr0KLfffjunTp3CZrM5X8NgMBASEsKxY8dc7i+NyWQqVO/i6pqRkVGoTtWrVweg\nffv2BAQEsHnzZo4ePUqXLl0IDg4u9X1FiqOWt/itp556il69epGcnMzKlSsJDw8v9/cIDQ0lOzvb\nuX38+HGXj/vyyy9Zt24dixcvJjk5mZEjR7r1+jVq1Cg0kr7gnPGlbrrpJnbv3s2+ffvYt28fN954\nI1D2z6C499u2bRsLFizgjTfeIDk5mb///e+llr127dqcOnXKuX3q1Clq165d6vMu9vzzz9O8eXNW\nrFjBypUradmyJQDh4eEYDAYyMjIAsNvt7N+/v9j9dru9yBez06dPu3zPkuoaHh7ufG1whHnBdr9+\n/Vi5ciUrV6509l6IXC6Ft/itEydO0KZNGwwGA0lJSeTk5BQK2vLQtm1bNm3axMmTJ8nLy+Nf//pX\nsWVp0KABERERZGRksGLFCrKyskp9/Xbt2jnPBW/bto0DBw64fFxgYCBdunThpZdeonv37phMJuf7\nluUzKO79Tp48SWRkJPXr1ycnJ4ekpCSys7Ox2+2YzWays7OxWCyFXuuWW25h9erVznD78MMPiYuL\nK7XOFztx4gStWrXCZDLx3XffsX//frKzswkMDKRz584kJSUB8M033zB06NBi9xsMBqKioti9ezfg\n+DJ17tw5l+9ZUl27devGunXrOH36NBaLhccee4xvv/0WgP79+7NmzRp++umnMtdT5FIKb/Fbo0aN\n4rHHHuPWW28lOzubu+66i0mTJhUbgJejbdu2JCQkkJCQwKBBg4o9z9m/f39OnTpFfHw8Y8aMYfTo\n0Rw9erTQqHVXnnrqKdavX0+PHj1YsmQJf/rTn4p9bK9evVizZg19+vRx7ivrZ1Dc+910001ER0fT\no0cPBg8ezP33309YWBgjR46kRYsW1KxZk86dOxcaL9C2bVuGDh3KwIED6d27N2fPnuWJJ54osb6X\nevTRR5k5cyb9+/dn8+bNjBgxgldeeYWtW7cydepU1q9fT/fu3ZkzZw6zZs0CKHb/8OHD+ec//0n/\n/v3Zu3cv11xzjcv3LKmu7dq1Y8iQIfz5z3+mX79+xMbGOs+vt2jRglq1atGlSxeqVatWpnqKXMqg\n63mLeJbdbneeE92wYQNz5swptgUuVdvDDz/Mvffeq5a3XDG1vEU86OTJk9x4440cOnQIu93OihUr\nnKOUxb9s3bqVQ4cOcdNNN1V2UaQK8Gh479mzhx49erB48eIi933//ff85S9/4a677uK1117zZDFE\nKk1ERASjR4/mgQceoFevXpw+fZrHH3+8soslFWzChAlMnDiRGTNmOKcqilwJj3WbZ2dnM2zYMJo0\naUKLFi2cKxMV6Nu3L2+//TZ16tTh3nvv5fnnny/2HJOIiIhc4LGvgIGBgSxYsKDQnMcCqamp1KxZ\nk3r16mE0GomLi2Pjxo2eKoqIiEiV4rHwNpvNxY6oTEtLIyIiwrkdERFBWlqap4oiIiJSpfjMCmtp\naWfdelx4eDAZGeU7V7cyqT7eTfXxbqqPd1N9ShcVFeZyf6WMnIiOji50Pd9jx4657F6/HGazqVxe\nx1uoPt5N9fFuqo93U30uX6WEd8OGDcnMzOTgwYNYLBbWr19P586dK6MoIiIiPsdj3eY7duxg5syZ\nHDp0CLPZ7Lx0XsOGDYmPj2fKlCmMGTMGcIw8v/giDCIiIlI8j4V3mzZtWLRoUbH333DDDSxbtsxT\nby8iIlJlabUAERERH6PwFhER8TEKbxERER+j8BYREfExPrNIizd65ZV/8OuvKZw8eYLc3Fzq129A\njRo1mTbtpVKf++WXnxMSEkpcnOvrO8+dO5s77xxAVFTL8i62iIj4OL8K76QkM3PmBLJnj5GYGBuj\nR+eRkGC57Nd7/PEnAEcQ//e/exkxYrTbz+3b99YS7x81asxll0tERCrOhWyBmJjgK84Wd/hNeCcl\nmRk2rLpzOyXFdH47p9w/5G3btvDhh4vJzs5mxIgn+OmnrWzYsBabzUanTp0ZPHgob789n1q1atG0\naTMSE5djMBjZv/9/3HJLdwYPHsqIEUN58slxfPjhtxw/foIDB/Zz6NBBRo4cQ6dOnVm8+J+sWbOK\n+vUbYLFYGDBgIB06XO8sw48/bmLhwjcJCAggLCyM55+fQUBAAHPmzGLXrh2YTCaeemoCV199jct9\nIiJSuorMlov5zTnvOXMCXe6fO9f1/iu1d+/vvPzyq7Rs2QqA119fyFtv/ZMVK74gKyuz0GN37drJ\n3/42hTfffJdPPik69/348WPMmjWPUaPG8tlniZw5c5rExI+YP/8dxo4dz88/byvynLNnzzJ58t95\n9dW3CA4OYdOmjfz44yaOHz/GW2/9k2HDHmPt2tUu94mIVFVJSWbi4oKpVy+UuLhgkpKKb8O689iK\nzpYCftPy3rPH9feU4vZfqWuuaU5goOPgVatWjREjhmIymTh16hRnzpwp9NgWLVoWewU2gLZt2wGO\nNeEdy8qmcvXVzQgKqkZQUDVatWpd5Dm1atVi5sy/Y7VaOXz4ENdddwMZGSf5wx+uBaBduw60a9eB\nJUveK7JPRMTXuHNatCytZHcfW9HZUsBvWt4xMbYy7b9SAQEBABw9eoRly5Ywe/YrvPrqW9StW7fI\nY02mkhezv/h+u92O3Q5G44VDZzAUfc706S/wxBPjePXVt+jS5WYAjEYTdnvh+rraJyLiLdxp/RYE\nbUqKCavV4AzaSx9bllayu4+t6Gwp4DfhPXp0nsv9o0a53l9eTp06RXh4OMHBwfz6626OHj1Kfn7+\nFb1mvXr1+O9/92KxWMjIyGD37pQij8nKyqROnbqcPXuWbdu2kp+fT6tWsWzbtgWAPXt2M3v2TJf7\nREQ8qSCQzWZK7Lou71AuSyvZ3cdWVrb4TXgnJFiYPz+H2FgrZrOd2Fgr8+d7dkABQPPmMVSvHsyj\njw5m7dpV3Hbb7VcckBERkcTH9+bhhwcxd+4sYmNbF2m93377nTz66BBefHEqAwcOYvHif9Kw4VU0\nbtyU4cMfYs6cWfz5z3fQrl2HIvtERAqU9zniwoFMsYEM5R/KZWklu/vYwtlChWWLwW632z36DuUk\nLe2sW4+Ligpz+7G+oLj6fPnl58TH98ZkMjFo0ABefvkVoqPrVEIJy8Zfjo+vUn28W0XX59LzvgVc\nhZO7j42LCyYlpeipwthYKxs2ZBfaV69eKFZr0fOCZrOdw4cvDPx19zU9UZ+LeeL4REWFudzvNy3v\nqubEiRMMHXo/jzwymJ49e/tEcIuI9yjvkdSe6Lp2t/Xrbtd1WXpgK6u31l1qeXs51ce7qT7ezR/r\nczmjrgtcGk7utnzL8tiytLzL2lKeO/dCvUeN8vxCKZdSy1tERMqsvAd4eeIccVkGeJW1pbxhQzaH\nD2eyYUO217SQPUXhLSJSSdwdDObu6Ozy7rouS9BeXtd16QO8/C2U3eU3i7SIiHgTdxcBKcvCImUZ\nde2q69rVSGrIcas7uqyPTUiwnO9mzi5yv5ROLW8RkXLkbmva3VZyWQaNearr2t2Wr1rJFUfhfQWG\nDXuwyAIpb775KkuXLnb5+G3btvDMM+MAGD/+ySL3f/LJMt5+e36x7/f7779x4MB+ACZPnsC5c7mX\nW3QR8QB3zzmD+63ksozO9sSoa/FOCu8rEB/fi3XrCl/IY8OGdfTo0bPU586Y8XKZ3++rr9aRmnoA\ngOeem05QUPHroYtI+SrvqVXutpLLMmhMA7z8h855X4Hu3Xvy6KNDGD58JAC7d6cQFRVFVFS0y0ty\nXqxfv+78+99r2bJlM/PmzSYiIpLIyNrOS3xOnTqFtLTj5OefY9Cgh6hbtx6ffprIV1+tIzw8nGef\nncD77y8jM/Ms06c/T35+PkajkfHjJ2EwGJg6dQr16zfg999/IyamBePHTyr0/qtWreDjj5dhMhlp\n0qQZTz/9NywWC3//+2SOHTtCYGAQzzzzHOHhEUX2RUVFV9hnLOJp5XlBi7K2kl1Ng7q0lezu4woU\nnE+Wqq3KhPeUKUF8/rkZoxFstpByec1bb7UwZcq5Yu8PD4+gfv0G7Nq1g9jYNqxbt5r4+N7AhUty\n1q/fgBdeeJZNmzYSHBxc5DXmz3+VSZNeoHnzGMaOHUn9+g04e/YMHTveSJ8+/cnNPcXw4SN4553F\n/PGPnbjllu7ExrZxPn/hwjfp3/82unfvyfr1a3jnnbcYMmQYv/6awnPPTSM8PIKEhL6cPXuWsLAL\n8wVzcnKYPfsVwsLCeOyxh9m793d27dpBZGQkU6ZMZc2aZL799mvMZnORfQkJfymXz1eksrkbyiW1\nqC9+nLsDwcD9AV6FH2ciJsZaKXOYxbtUmfCuLPHxvVm7djWxsW347ruveeONdwDXl+R0Fd5Hjhyh\nefMYwHFJznPnzhEWVoOUlJ189lkigYEBnDlzutj3//XXFB55ZAQAHTpczz//uRCABg0aERlZG4Da\ntaPIysosFN41atRgwoQxAOzf/z9Onz7Fr7/u5vrrbwCgR49eAMyaNaPIPhFvd6E1DTExwS5b0+B+\nKJdlapUnWskanS2XqjLhPWXKOaZMOXf+lzurwt43Lq4r77//DvHxvWjU6Cpq1KgBOC7J+dJLc2jS\npCkvv1z8hUguvrRnwWJ3q1ev5MyZM7z22kICAqwkJNxeQgkMzufl51swGByvd+mFSi5eSC8/P5+X\nX36Rf/7zAyIjazNu3OjzzzFisxVecM/VPhFv5itTq0SuhAasXaHg4BCaNWvO+++/6+wyB9eX5HSl\ndu0oDhzYh91u56eftgKOy4jWq1cfo9HI6tWrnc81GAxYrdZCz7/4kp4//7yVli1blVrm7OwsTCYT\nkZG1OXbsKLt3p2CxWGjZMpZt234E4LvvvuH9999xuU+kslTWoDFPTa0SuVwK73IQH9+bH3/cRJcu\nNzv3ubok54kT6UWeO3TocJ555mmefvoJ58VFbrmlG99//w2jRj1K9erViY6O5t13F3Dtte2ZM+cl\ntmzZ7Hz+Qw89wsqVXzJy5CN8+eUXDBkyrNTy1qxZixtu+CMPPTSId99dwD333Me8eS/TvXtPcnJy\nGDFiKMuXL6VPn/706NGryD6RyuDuNCxNrRJ/oAuTeDnVx7upPlfOndHe4P4FLcpy4YuC9/eVbm79\nvnm3irwwSZU55y0ivscT56c1tUr8gbrNRcQjKuv8dFkvfCHii9TyFpFyV5mLmoCmVknVp5a3iJRJ\nebaoPbX0p0hVp5a3iLitvFvUOj8tcnnU8hYRt5V3i1qtaZHLo/AWEWdXuNlMidegLkuL2hUtaiJS\nPhTeIn6u8OInlHgNarWoRbyDwlukCivv6VpqUYt4Bw1YE6miPDFdSxfeEPEOanmL+Bh3WtPgmela\noBa1iDdQeIv4EHcvzgGeGVwmIt5B4S3iJbScqIi4S+e8RbyAlhMVkbJQy1vEC2g5UREpC4W3iIe5\n0x3uqfPTGlwmUjUpvEU8yN0BZlr8RETKQuEt4kHudodr8RMRKQuFt8hlKO+1wNWiFpGy0GhzkTJy\nd2Q4OLq9U1JMRV6juAFmCmsRcYda3iJl5Km1wEVE3KXwFrlIeY4MB3WHi4hneLTbfNq0aWzfvh2D\nwcDEiRNp27at8741a9bwxhtvEBgYSL9+/bj33ns9WRSRUrnbHV6WrnBQd7iIlD+Ptbw3b97M/v37\nWbZsGVOnTmXq1KnO+2w2Gy+88AILFixgyZIlrF+/nqNHj3qqKCJu8cTIcBERT/BYeG/cuJEePXoA\n0KxZM06fPk1mZiYAGRkZ1KhRg4iICIxGIzfeeCPff/+9p4oifs7dq3Bd3shwrQUuIhXPY+Gdnp5O\neHi4czsiIoK0tDTn7aysLPbt20d+fj6bNm0iPT3dU0URP1aWq3CVdenRDRuyyc9Hc61FpMJV2FQx\nu93uvG0wGJgxYwYTJ04kLCyMhg0blvr88PBgzOai5xldiYoKu+xyeiPV5/K9+qrr/a+9Vp2hQwvv\ne/ZZuPvuoo+dNMlUYpl1fLyb6uPdVJ/L47Hwjo6OLtSaPn78OFFRUc7tjh078sEHHwAwe/ZsGjRo\nUOLrZWS4d6Ujx1WRzl5Gib2T6lO8pCQzc+YEsmePkZgYG6NH5xVpAe/aFQoYijx31y47aWmZhfZ1\n7w7z55uZO/fCa44alUf37hbOdxp5tD7eQPXxbqqPd/NEfYr7MuCxbvPOnTuTnJwMwM6dO4mOjiY0\nNNR5/0MPPcSJEyfIzs5m/fr1dOrUyVNFkSqovNcML6ClR0XEF3is5d2hQwdat27NgAEDMBgMTJ48\nmcTERMLCwoiPj+evf/0rgwcPxmAwMHToUCIiIjxVFKmCShoZfnHgluWa1iIivsKj57zHjh1baLtl\ny5bO2z179qRnz56efHupwsoyMhxyinSFq0UtIr5Ma5uLT9Ka4SLiz7Q8qngdd+Zla6EUEfFnanmL\nV3F3iVJ1h/uX/Hw4c8bA6dOOn2fOGMjMNJCZyfmfBrKyHLfPnr2wPzAQ6tQJolEjO40a2WjUyMZV\nV9mJjrZjLEPTxWaDs2fh1CkDOTkGrFbHPqv1wj+bzVBon831mEiXcnMNZGdDVpajHtnZBuftrKwL\n91kskJMTjMXCRf8Ml2yD1WogMNBO9eoQHGwnOBiqV3dsV69eeDs42E5IiGNfSIidkJAL+y7cdvw0\nFJ24UYTd7qh7Xp6B/HzIy3OUqfC2gbw8qFULwEh4uJ3wcMf7uPMeovAWL+PuQDRQd3hFs9vhzBk4\nedLAqVOOkLw4KLOyCodpwW2rFUwmMJvBbLZjNkNAwIV9AQF2TCbHH+2zZx3BfOpUQVg7/mVnX8lf\n9KK/U4GBdho2tJ8Pcxv169vJy3OEs6t/p087wrmyGQwQEGDEbHZ8fgWfXcFnGhjo+IxNJjt5eY7Q\nP3XKSE6OIzy9U4jzVmCgI8QjIuzOQC+4Xa2ao34BAfbz9XQ8vqDejp+OLyQXPy/Q9Z8Un6fwFq9S\nlit2+SOLBQ4eNLBvn5GjRw3OP9oFf7gu/gNe8ActIMDREszLg9xcxx/xvDw4d85QZB9AamoQGRkG\nMjIcQe247fhntVZMABiNdmrWhBo17FxzjY2aNe3UqGE//xPCwuyEhtoJDS18OyTkwu3QUDuRkWH8\n/HMWBw4YOHDASGqqkdRUg/PnV18V/ycwMNBOrVp2oqNtNG9uJzwcata0ExzsCEyTCYxGzt+2O7cL\n9hmN7rcig4IubvkWbvFe3Cpu2DCM9PTM0l/QBYvFcayzsgzk5EBOjuNnQcv+4ta+43bhfTk5Bi5a\na6tEZrPd+bt38e+m49+F383q1YM4dCjP+YUwI8PAyZMGDh82kpJSPr9rISEXgrxWrcJfDKpVc3z2\ngYEQFOS4HRTkKK9j23E7L89RNseXOddf8jIyDEREQGIiXDQr2mMU3uJVynrFrqooKwv27zeyb5+R\nffsM5386/h08aMBi8XSAXmiqGI0Ff/SgSRNboT+CNWo4gjIsjPOBeSE0L74dEOAIjvx8x5eIi7t5\nC/bl5zuCoSCgy6v7NCTE8bsTEwNgLXJ/VhYcPGjk0CED1apBrVqO+tWs6WjBeVsX7pWUx2zGeUwc\n3ExiD4qKCiIt7ZzL+ywWCgX6uXMF3e+O3xfHzwvd8QW3s7Jwftm8+Mvn778br7AHp3jVqxd8MXB8\ncasICm+pEBdWQ4OYmGCXq6GB/83LttkcvQqbNpnYtMnE5s0mDhxw3ctQu7aNdu1sNGni+Fe/vh27\n3fU5RccfswvbJtOFlsXFrYyC24GBjlZI3brVMRqznN2ONWpQpnPDxSl4fwdXoVE5QRISAi1a2GjR\nolLeXkpgNkPt2nZq1y6/343cXJyhfvq0gdzcCz1Q584VvX3unOP/T2Cg44vdhX84v8TWrOn4vwMF\nK6yVW3FLpPAWj3N3EBpU/YFoubnw88+OkN60ycSPP5o4depCayA83M5NN1lo2rQgpO3OsK6Irrio\nKEhL859eDvEv1apBvXp26tWr/F6HK6XwFo8ryyA08L2BaBaLYyRywWCrzEwDZ844BlwVDOpKTzew\nbZuRn382FRo41LixjZ49Lfzxj1Y6drTSvLmtXFq6IlK1KbzF43xpENqxYwa2bzeSnm5whq/jJxfd\ndmw7ghqysty7ipDRaOcPf7A5g7pjRyt16/p+C0BEKp7CWzzOWwehZWbC9u0mtm0z8dNPRn76ycSh\nQ6V/oQgMdAzWCguDBg0gONhCWJhj27Hf8a9gVHSNGo5/rVpVTNe3iFR9Cm/xOG8YhGa1ws6dxvNB\n7QjrX381Yrdf6MKuXdtGr14W2rWz0qCBrVD4XhzOFwZeFQxQyamweoiIgMJbrpA719QuPAjNREyM\ntUIGoeXmwrffmlixwsyKFWbS0y+0qoOD7XTqZKV9exsdOlhp395KgwburSAlIlLZFN5y2co6ijwh\nwXK+pZrtsTKdOQNr1pj58ksza9eaycpypHHt2jbuuSePjh0dgR0TY6uw+ZgiIuVN4S2XrayjyD3l\n6FGDs3X93Xcm8vMdgd2kiY3778+nTx8L119vVViLSJWh8JbLVtGjyO12OHLEQEqKkV27TOzaZWTX\nLmOhwXBt21rp29dCnz4WWra0qRtcRKokhbdcNk+OIj97FlJSHMHsCGvH7dOnC6dxcLCdLl0s9O1r\noXdvCw0bauqViFR9Cm+5bJ4YRb5zp5FXXgnk00/NhS6CYTTaadrUzs03W2jVykarVjZiY600bly2\nSzuKiFQFCm+5bOW1lKndDj/8YGLevEDWrnX8SrZqZeXmm620bm2lVSvHALPqRb8niIj4JYW3FOHO\n9K8CV7KUqc0GyclmXnklkC00JefkAAAgAElEQVRbHN3vnTpZePzxPLp3t+p8tYhIMRTeUkhZpn9d\nrrw8SEw08+qrjnnfAL175zNiRB4dO+qiGCIipVF4SyGenP515gwsWQKzZoVw6JARs9nOXXc5QrtF\nC4W2iIi7FN5SSHlO/8rPh61bTXz9tYmvvjKzbZsRqxWCgw0MG5bHsGF5Gh0uInIZFN5SyJVM/7Lb\n4bffjHz1lSOsv/vO5FzhzGSy0769jYQEE3fckUlERLkXXUTEbyi8pZCyTv+yWODLL82sXm3m669N\nHDlyoYXerJmNuLh8br7ZSpcuFmrUKLiQh8eKLyLiFxTeUoi7079sNvjiCzMzZgTy+++OlnpkpI2E\nhHzi4izcfLNVXeIiIh6i8JYiSpr+ZbfD+vUmpk0L4j//MWEy2bnvvjweeCCf1q1tWjBFRKQCKLzF\nbT/8YGLatEB++MGMwWDn9tvzGTfuHFdfrRa2iEhFUnhLqX75xcj06UGsWeP4denVy8L48edo3VrT\nu0REKoPCW4r1++8GZs4M4tNPAwDo3NnCxInnuOEGhbaISGXSGUo/kpRkJi4umHr1QomLCyYpyfV3\nN4sFpk0L5KabQvj00wDatbOyfHk2iYk5Cm4RES+glrefcHfZ02PHDAwbVo3vvzfTuLGNyZNz6dfP\nonXGRUS8iFrefqKkZU8LfP+9ie7dg/n+ezN9++azdm0W/fsruEVEvI3C20+UtOypzQbz5gVy++3V\nOXnSwHPP5fLuu7nUqFHBhRQREbeo29xPFLfsabNmNgYNqs6qVWbq1bPx1lu5/PGP1koooYiIuEst\nbz8xerTr5U3T0w2sWmUmLs7C2rXZCm4RER+g8PYTCQkW5s/PITbWislkp25dG2aznZMnDYwde44P\nP8yhdm0ttiIi4gsU3n4kIcHCF19k83//Z+HoUSM1a9r58MMcxo3Lw1S0R11ERLyUznn7kZMnISEh\nmJQUE9dfb2Xhwhzq11drW0TE16jl7SeysmDgQEdw33dfHp9+mq3gFhHxUQrvKqC0ldPy82HIkOps\n3WrijjvyeemlcwQEVFJhRUTkiqnb3MeVtnKazQYjR1Zj3Toz3btbmDcvV5ftFBHxcfoz7uNKWjnN\nbofJk4P45JMArrvOcY5bLW4REd+n8PZxJa2c9sorgcyfH0iLFlY++CCbkJAKLpyIiHiEwtvHxcS4\nvspXVJSdv/89iAYNbCxblkN4eAUXTEREPEbh7eOKWznt6FEDERE2li/XdDARkapG4e3jLl45zWy2\n07ix42f16vDBBzk0b67rb4uIVDUK7yogIcHChg3ZrFqVzcmTRgwGePfdHDp0UHCLiFRFmipWRezb\nZ+Cuu6qTmQlvvJFL1666wIiISFWl8K4CDh828Ne/BpOWZmTatFxuv91S2UUSEREPUre5j9u82Uh8\nfDD79hl58slzPPRQfmUXSUREPMyjLe9p06axfft2DAYDEydOpG3bts77lixZwmeffYbRaKRNmzb8\n7W9/82RRqqQlSwIYNy4Imw2mTctlyBAFt4iIP/BYeG/evJn9+/ezbNky9u7dy8SJE1m2bBkAmZmZ\nvP3226xatQqz2czgwYP5+eefadeunaeKU6Xk5ztWTlu4MJBatewsXJjDzTfrHLeIiL/wWHhv3LiR\nHj16ANCsWTNOnz5NZmYmoaGhBAQEEBAQQHZ2NsHBweTk5FCzZk1PFaVKOXkSHn64Ot98Y6ZlSyvv\nvZdD06aaxy0i4k88Ft7p6em0bt3auR0REUFaWhqhoaEEBQXx2GOP0aNHD4KCgujXrx9NmzYt8fXC\nw4Mxm01uvXdUVNgVld3bFNTnl1/gttvgf/9z/Fy0yERYWGgll67squrxqSpUH++m+ni3iqpPhY02\nt9svtA4zMzOZP38+K1euJDQ0lPvvv5/du3fTsmXLYp+fkZHt1vtERYWRlnb2istb2ZKSzMyZE8ie\nPSZiYqzExVl4//1AsrMNjBlzjqeeyiM3F3JzK7ukZVNVjk8B1ce7qT7eTfVx7zVd8Vh4R0dHk56e\n7tw+fvw4UVFRAOzdu5dGjRoREREBwPXXX8+OHTtKDG9/4uoynykpJgID7bz9dg633qqpYCIi/sxj\nU8U6d+5McnIyADt37iQ6OprQUEcXb4MGDdi7dy+555uNO3bsoEmTJp4qis8p7jKfDRvaFNwiIuK5\nlneHDh1o3bo1AwYMwGAwMHnyZBITEwkLCyM+Pp4hQ4YwaNAgTCYT7du35/rrr/dUUXxOcZf5PHBA\n0/JFRMTD57zHjh1baPvibvEBAwYwYMAAT769z2re3Mbu3UUH5xV3+U8REfEvasp5oauuch3So0a5\nvvyniIj4F4W3l3nvvQBWrQqgTh0bLVpYMZshNtbK/Pk5JCTofLeIiOjCJF5l3ToT48cHERlp47PP\nsmna1H5+6oF70+RERMQ/qOXtJXbsMDJkSHUCAuD997VqmoiIFK/U8N67d29FlMOvHT5sYODA6mRl\nGXjttVxuuEED00REpHilhvfIkSO5++67+eSTT8jJyamIMvmVzEwYOLA6R44YefbZXM3jFhGRUpV6\nzvvf//43e/bsYcWKFdx33320atWKO++8s9DlPeXyWCyOi4zs3Gli0KA8HntMl/QUEZHSuXXOOyYm\nhlGjRjF+/Hj27t3L8OHDGThwIPv27fNw8aouux0mTAhi7Voz3bpZmDHjHAZDZZdKRER8Qakt70OH\nDpGUlMQXX3zBNddcwyOPPMJNN93EL7/8wlNPPcVHH31UEeWscl5/PYD33gukdWsrCxfmYNa4fxER\ncVOpkXHffffxl7/8hffee486deo497dt21Zd55fp88/NPPdcNerWtbFkSQ6hvndVTxERqUSldpt/\n9tlnNGnSxBncS5cuJSsrC4BJkyZ5tnRV0G+/GXnssWqEhNhZsiSH+vU1JUxERMqm1PCeMGFCoUt7\n5ubmMm7cOI8Wqqqy2WDs2CBycw3Mm5fLH/6gKWEiIlJ2pYb3qVOnGDRokHP7wQcf5MyZMx4tVFX1\n4YdmNm4006dPvqaEiYjIZSs1vPPz8wst1LJjxw7y8zWlqazS0gxMmeLoLp827VxlF0dERHxYqQPW\nJkyYwPDhwzl79ixWq5WIiAhefPHFiihblTJ5chCnThmYOjWXBg10nltERC5fqeF97bXXkpycTEZG\nBgaDgVq1arFt27aKKFuV8dVXJj7+OIBrr7UyeLB6LURE5MqUGt6ZmZl8+umnZGRkAI5u9E8++YRv\nv/3W44WrCnJyYNy4ahiNdmbPzsVkquwSiYiIryv1nPfo0aP59ddfSUxMJCsri/Xr1zNlypQKKFrV\nMGdOIP/7n5GhQ/Np29ZGUpKZuLhg6tULJS4umKQkrc4iIiJlU2p4nzt3jueff54GDRrw9NNP8/77\n77NixYqKKJvP273byKuvBtKggY1x486RlGRm2LDqpKSYsFoNpKSYGDasugJcRETKxK3R5tnZ2dhs\nNjIyMqhVqxapqakVUTafZrPBU08FkZ9vYMaMXEJDHa1wV+bOdb1fRETElVKbfLfddhvLly/nzjvv\npG/fvkRERNC4ceOKKJtPW7IkgE2bzPTvn0+vXlYA9uxx/V2puP0iIiKulBreAwYMwHD+cledOnXi\nxIkTtGrVyuMF82XHjxt4/vkgQkPtTJ16YU53TIyNlJSiI9ZiYrTSmoiIuK/UJt/Fq6vVqVOH2NhY\nZ5iLa88+G8Tp0wb+9rdz1Kt3YU736NF5Lh8/apTr/SIiIq6U2vJu1aoVc+fOpX379gQEBDj3d+rU\nyaMF81Xr1plITAygQwcrDzxQeE53QoIFyGHu3ED27DESE2Nj1Ki88/tFRETcU2p4p6SkALBlyxbn\nPoPBoPB2ITvbMafbZLIza5brOd0JCRaFtYiIXJFSw3vRokUVUY4q4R//COTAASOPPZZHmzY6jy0i\nIp5Ranjfc889Ls9xL1myxCMF8lUpKUZeey2QRo1sjB2rC4+IiIjnlBreo0ePdt7Oz8/nhx9+IDg4\n2KOF8kULFgRgsRiYNi2HkJDKLo2IiFRlpYZ3x44dC2137tyZhx9+2GMF8lVbtpgIDrbTo4e1sosi\nIiJVXKnhfelqakeOHOF///ufxwrki86ehV9/NdKpk1UXHhEREY8rNbzvv/9+522DwUBoaCgjRozw\naKF8zU8/mbDbDVx3nVrdIiLieaWG97p167DZbBiNjvVc8vPzC833Fti2zdHc7tBBI8xFRMTzSl1h\nLTk5meHDhzu3Bw4cyMqVKz1aKF+zdasjvNXyFhGRilBqeL/77ru89NJLzu133nmHd99916OF8iV2\nO2zdaqR+fRt169pLf4KIiMgVKjW87XY7YWFhzu3Q0FCtbX6R1FQD6elGtbpFRKTClHrOu02bNowe\nPZqOHTtit9v55ptvaNOmTUWUzSdcON+t8BYRkYpRang/88wzfPbZZ/znP//BYDDwf//3f/Tu3bsi\nyuYTLpzv1mA1ERGpGKWGd05ODgEBAUyaNAmApUuXkpOTQ4iWEQMc4W0y2WnbVi1vERGpGKWe8376\n6adJT093bufm5jJu3DiPFspX5OXBL78YiY21oRVjRUSkopQa3qdOnWLQoEHO7QcffJAzZ854tFC+\nYudOI+fOGQgPtxMXF0y9eqHExQWTlFRqh4aIiMhlKzW88/Pz2bt3r3P7l19+IT8/36OF8hUFg9W+\n/tpMSooJq9VASoqJYcOqK8BFRMRjSk2YCRMmMHz4cM6ePYvNZiM8PJwXX3yxIsrm9QoGq7kyd24g\nCQmWCiyNiIj4i1LD+9prryU5OZkjR46wadMmkpKSePTRR/n2228ronxezRHedqDovPc9e0rt1BAR\nEbkspYb3zz//TGJiIl9++SU2m40XXniBnj17VkTZvNrJk/C//xkJCbGTlVX0/pgYTR0TERHPKLZ5\nuGDBAvr27csTTzxBREQEn3zyCVdddRX9+vXThUlwXEkM4JZbXHeNjxqVV5HFERERP1JseM+ZM4eA\ngACmT5/O6NGjady4sZZFvUjB+e577sln/vwcYmOtmM12YmOtzJ+fo/PdIiLiMcV2m2/YsIGkpCQm\nT56MzWYjISFBo8wvUhDe7dvbqF3brrAWEZEKU2zLOyoqiqFDh5KcnMy0adM4cOAAhw4d4pFHHuGr\nr76qyDJ6Hbvd0W3euLEjuEVERCqSW0Oib7jhBmbMmME333zDLbfcwmuvvebpcnm1//7XwKlTBl1J\nTEREKkWZ5jOFhoYyYMAAli9f7qny+IQtWwouRqLwFhGRiufRZcCmTZvG9u3bMRgMTJw4kbZt2wJw\n7Ngxxo4d63xcamoqY8aM4dZbb/VkccqNLgMqIiKVyWPhvXnzZvbv38+yZcvYu3cvEydOZNmyZQDU\nqVOHRYsWAWCxWLjvvvvo1q2bp4pS7rZtMxEYaKdNG83lFhGRiuexZcA2btxIjx49AGjWrBmnT58m\nMzOzyOOSkpLo1auXz1xiNCfHcUGSP/zBRlBQZZdGRET8kcda3unp6bRu3dq5HRERQVpaGqGhoYUe\n99FHH/HOO++U+nrh4cGYzcWvJX6xqKiwshW2DL77DiwW6NzZ5NH3uVhFvU9FUX28m+rj3VQf71ZR\n9amwS1/Z7UWnVP30009cffXVRQLdlYyMbLfeJyoqjLS0s2Uun7vWrg0AqtGqVQ5paZ6f2+3p+lQ0\n1ce7qT7eTfXxbp6oT3FfBjzWbR4dHU16erpz+/jx40RFRRV6zIYNG+jUqZOniuARBYPVNNJcREQq\ni8fCu3PnziQnJwOwc+dOoqOji7Swf/nlF1q2bOmpInjE1q0mIiNtNG6sxVlERKRyeKzbvEOHDrRu\n3ZoBAwZgMBiYPHkyiYmJhIWFER8fD0BaWhqRkZGeKkK5O3bMwMGDRuLjLWiZdxERqSwePed98Vxu\noEgr+/PPP/fk25c7dZmLiIg38Fi3eVW0davj49LiLCIiUpkU3mVQ0PJu317hLSIilUfh7Sar1XEl\nsebNrdSsWdmlERERf6bwdtOvvxrJyjJw3XVaElVERCqXwttNuhiJiIh4C4W3m7Ztc3xUGmkuIiKV\nTeHtpq1bTVSvbqdVK3Wbi4hI5VJ4uyEzE3bvNnLttVbMFbYavIiIiGsKbzf8/LMJu91Ahw5qdYuI\nSOVTeLtBK6uJiIg3UXi7YcsWDVYTERHvofAuhd3uaHnXrWujfn1dSUxERCqfwrsUhw4ZOH7cqPnd\nIiLiNRTepdi6teB8twariYiId1B4l+JCeKvlLSIi3kHhXYpt24wYjXbatlV4i4iId1B4l8Bmg19+\nMdGihY3Q0MoujYiIiIPCuwTHjxvIyTHQvLnOd4uIiPdQeJfgwAEDAI0aaYqYiIh4D4V3CVJTHR9P\no0ZqeYuIiPdQeJegILyvukrhLSIi3kPhXQJ1m4uIiDdSeJfgwAHHx9OwoVreIiLiPRTeJUhNNVK7\nto2QkMouiYiIyAUK72LYbHDwoEFd5iIi4nUU3sU4dsxAfr5BI81FRMTrKLyLUXC+WyPNRUTE2yi8\ni5GaqpHmIiLinRTexdAcbxER8VYK72Ko5S0iIt5K4V0MzfEWERFvpfAuRsEc7+Dgyi6JiIhIYQpv\nF6xWxxzvq65Sl7mIiHgfhbcLmuMtIiLeTOHtQsH5boW3iIh4I4W3CxppLiIi3kzh7ULBHO/GjdXy\nFhER76PwdkEtbxER8WYKbxc0x1tERLyZwtuF1FQjUVE2qlev7JKIiIgUpfC+hNUKhw5pjreIiHgv\nhfclLp7jnZRkJi4umHr1QomLCyYpyVzZxRMREUFpdImC8905OTBs2IV+85QU0/ntHBISLJVUOhER\nEbW8izhwwDHSfPt2k8v7584NrMjiiIiIFKHwvkTBHO/jxw0u79+zRx+ZiIhULiXRJQrmeDdp4nqa\nWEyMpo+JiEjlUnhfoqDl/cQTeS7vHzXK9X4REZGKovC+xIEDRqKjbdx1l4X583OIjbViNtuJjbUy\nf74Gq4mISOXTaPOLFMzxvvZaR9d4QoJFYS0iIl5HLe+LHD1qwGIxcNVVOq8tIiLey6Mt72nTprF9\n+3YMBgMTJ06kbdu2zvuOHDnCk08+SX5+PrGxsTz//POeLIpbCs536zreIiLizTzW8t68eTP79+9n\n2bJlTJ06lalTpxa6f8aMGQwePJiPP/4Yk8nE4cOHPVUUtxXM8dbVxERExJt5LLw3btxIjx49AGjW\nrBmnT58mMzMTAJvNxtatW+nWrRsAkydPpn79+p4qitvU8hYREV/gsfBOT08nPDzcuR0REUFaWhoA\nJ0+eJCQkhOnTp3P33Xcze/ZsTxWjTAqWRtU5bxER8WYVNtrcbrcXun3s2DEGDRpEgwYNGDp0KBs2\nbOCWW24p9vnh4cGYza6XLL1UVFTYZZXx6FHHz3btQr3qcqCXWx9vpfp4N9XHu6k+3q2i6uOx8I6O\njiY9Pd25ffz4caKiogAIDw+nfv36XHXVVQB06tSJ3377rcTwzsjIdut9o6LCSEs7e1ll3rs3hOho\nyMzM4nwPf6W7kvp4I9XHu6k+3k318W6eqE9xXwY81m3euXNnkpOTAdi5cyfR0dGEhoYCYDabadSo\nEfv27XPe37RpU08VxS0WCxw+rOt4i4iI9/NYy7tDhw60bt2aAQMGYDAYmDx5MomJiYSFhREfH8/E\niRMZP348drudmJgY5+C1yqI53iIi4is8es577NixhbZbtmzpvN24cWOWLl3qybcvE400FxERX6EV\n1s7THG8REfEVCu/z1PIWERFfofA+ryC8dc5bRES8ncL7vNRUR7d5gwbqNhcREe+m8D7vwAEjderY\nqFatsksiIiJSMoU3jjnehw4ZNFhNRER8gsIbOHLEgNWqOd4iIuIbFN5osJqIiPgWhTea4y0iIr5F\n4Y3meIuIiG9ReKNucxER8S0KbzTHW0REfIvCG0fLu25dG0FBlV0SERGR0vl9eGuOt4iI+Bq/D++C\nOd4arCYiIr7C78Nbg9VERMTX+H14a463iIj4GoX3AbW8RUTEt/h9eGuBFhER8TUK71QDBoNdc7xF\nRMRnKLxTjdSta9ccbxER8Rl+Hd4WCxw+rGliIiLiW/w6vA8fLpjjrS5zERHxHX4d3prjLSIivsjP\nw1tzvEVExPf4dXgXzPHWOW8REfElfh3emuMtIiK+yK/D+8ABxxzvhg3VbS4iIr7Dr8M7NdVIvXp2\nAgMruyQiIiLu89vwzs/XHG8REfFNfhvehw8bsNk0x1tERHyP34a35niLiIiv8uPw1hxvERHxTX4b\n3prjLSIivspvw1tzvEVExFf5cXjrOt4iIuKb/Di8NcdbRER8k1+Gd8Ecb400FxERX+SX4X3okOZ4\ni4iI7/LL8NZgNRER8WV+F95JSWZGjgwCYOnSAJKSzJVcIhERkbLxq+RKSjIzbFh15/aRI8bz2zkk\nJFgqr2AiIiJl4Fct7zlzXA8tnztXQ85FRMR3+FV479njurrF7RcREfFGfpVaMTGuB6gVt19ERMQb\n+VV4jx6d53L/qFGu94uIiHgjvwrvhAQL8+fnEBtrxWy2ExtrZf58DVYTERHf4lejzcER4AprERHx\nZX7V8hYREakKFN4iIiI+RuEtIiLiYzx6znvatGls374dg8HAxIkTadu2rfO+bt26UbduXUwmEwCz\nZs2iTp06niyOiIhIleCx8N68eTP79+9n2bJl7N27l4kTJ7Js2bJCj1mwYAEhISGeKoKIiEiV5LFu\n840bN9KjRw8AmjVrxunTp8nMzPTU24mIiPgNj7W809PTad26tXM7IiKCtLQ0QkNDnfsmT57MoUOH\nuO666xgzZgwGg6HY1wsPD8ZsNrn13lFRYZdfcC+k+ng31ce7qT7eTfW5PBU2z9tutxfaHjlyJDfd\ndBM1a9bkscceIzk5md69exf7/IyMbLfeJyoqjLS0s1dUVm+i+ng31ce7qT7eTfVx7zVd8Vi3eXR0\nNOnp6c7t48ePExUV5dz+85//TGRkJGazmZtvvpk9e/Z4qigiIiJVisda3p07d+aVV15hwIAB7Ny5\nk+joaGeX+dmzZxk9ejRvvPEGgYGB/Pjjj/Tq1avE1ytLV4S6Ybyb6uPdVB/vpvp4N5/vNu/QoQOt\nW7dmwIABGAwGJk+eTGJiImFhYcTHx3PzzTdz1113ERQURGxsbIld5iIiInKBwX7pyWgRERHxalph\nTURExMcovEVERHyMwltERMTHKLxFRER8TIUt0lIRSroQiq/ZtGkTo0aNonnz5gDExMQwadKkSi5V\n2e3Zs4fhw4fzwAMPcO+993LkyBHGjRuH1WolKiqKl156icDAwMouptsurc/48ePZuXMntWrVAmDI\nkCHccsstlVvIMnjxxRfZunUrFouFYcOG8Yc//MGnj8+l9Vm3bp3PHp+cnBzGjx/PiRMnOHfuHMOH\nD6dly5Y+e3xc1Sc5Odlnj0+B3Nxc+vfvz/Dhw+nUqVOFHZ8qE97uXAjF13Ts2JF58+ZVdjEuW3Z2\nNi+88AKdOnVy7ps3bx733HMPffr04eWXX+bjjz/mnnvuqcRSus9VfQCefPJJunbtWkmlunw//PAD\nv/32G8uWLSMjI4OEhAQ6derks8fHVX1uvPFGnz0+69evp02bNjz88MMcOnSIwYMH06FDB589Pq7q\n0759e589PgXeeOMNatasCVTs37cq022uC6F4n8DAQBYsWEB0dLRz36ZNm+jevTsAXbt2ZePGjZVV\nvDJzVR9fdsMNNzB37lwAatSoQU5Ojk8fH1f1sVqtlVyqy9e3b18efvhhAI4cOUKdOnV8+vi4qo+v\n27t3L7///ruzt6Aij0+VCe/09HTCw8Od2wUXQvFlv//+O4888gh333033333XWUXp8zMZjPVqlUr\ntC8nJ8fZjRQZGelTx8hVfQAWL17MoEGDeOKJJzh58mQllOzymEwmgoODAfj444+5+eabffr4uKqP\nyWTy2eNTYMCAAYwdO5aJEyf69PEpcHF9wHf//wDMnDmT8ePHO7cr8vhUmW7zS/n62jNNmjRhxIgR\n9OnTh9TUVAYNGsSqVat85vyWO3z9GAHcdttt1KpVi1atWvHWW2/x6quv8uyzz1Z2scpkzZo1fPzx\nx7zzzjv07NnTud9Xj8/F9dmxY4fPH58PP/yQlJQUnnrqqULHxFePz8X1mThxos8en3/961+0a9eO\nRo0aubzf08enyrS8S7sQiq+pU6cOffv2xWAwcNVVV1G7dm2OHTtW2cW6YsHBweTm5gJw7Ngxn++C\n7tSpE61atQKgW7duPneBnW+++YY333yTBQsWEBYW5vPH59L6+PLx2bFjB0eOHAGgVatWWK1WQkJC\nfPb4uKpPTEyMzx6fDRs2sHbtWv7617/y0Ucf8frrr1fo/58qE96dO3cmOTkZoMiFUHzRZ599xttv\nvw1AWloaJ06cqBLniP70pz85j9OqVau46aabKrlEV+bxxx8nNTUVcJzvKpgd4AvOnj3Liy++yPz5\n852jfX35+Liqjy8fny1btvDOO+8AjtOC2dnZPn18XNXn2Wef9dnjM2fOHD755BOWL1/OnXfeyfDh\nwyv0+FSptc1nzZrFli1bnBdCadmyZWUX6bJlZmYyduxYzpw5Q35+PiNGjCAuLq6yi1UmO3bsYObM\nmRw6dAiz2UydOnWYNWsW48eP59y5c9SvX5/p06cTEBBQ2UV1i6v63Hvvvbz11ltUr16d4OBgpk+f\nTmRkZGUX1S3Lli3jlVdeoWnTps59M2bM4JlnnvHJ4+OqPrfffjuLFy/2yeOTm5vL3/72N44cOUJu\nbi4jRoygTZs2PP300z55fFzVJzg4mJdeesknj8/FXnnlFRo0aECXLl0q7PhUqfAWERHxB1Wm21xE\nRMRfKLxFRER8jMJbRETExyi8RUREfIzCW0RExMdU2RXWRAQOHjxI7969ad++faH9cXFxPPTQQ1f8\n+ps2bWLOnDksXbr0ivs6BjkAAAKOSURBVF9LRNyn8Bap4iIiIli0aFFlF0NEypHCW8RPxcbGMnz4\ncDZt2kRWVhYzZswgJiaG7du3M2PGDMxmMwaDgWeffZZrrrmGffv2MWnSJGw2G0FBQUyfPh0Am83G\n5MmTSUlJITAwkPnz5wMwZswYzpw5g8VioWvXrjz66KOVWV2RKkXnvEX8lNVqpXnz5ixatIi7777b\nee34cePGMWHCBBYtWsSDDz7Ic889B8DkyZMZMmQIS5Ys4Y477mDFihWA47KIjz/+OMuXL8dsNvPt\nt9/y/fffY7FY+OCDD/jwww8JDg7GZrNVWl1Fqhq1vEWquJMnT3LfffcV2vfUU08B0KVLFwA6dOjA\n22+/zZkzZzhx4gRt27YFoGPHjjz55JMA/Oc//6Fjx44A9OvXD3Cc87766qupXbs2AHXr1uXMmTN0\n69aNefPmMWrUKOLi4rjzzjsxGtVWECkvCm+RKq6kc94Xr45sMBgwGAzF3g+4bD2bTKYi+yIjI/n0\n00/56aefWLt2LXfccQdJSUkur4cuImWnr8IifuyHH34AYOvWrbRo0YKwsDCioqLYvn07ABs3bqRd\nu3aAo3X+zTffAPDll1/y8ssvF/u63377LRs2bOC6665j3LhxBAcHc+LECQ/XRsR/qOUtUsW56jZv\n2LAhALt27WLp0qWcPn2amTNnAjBz5kxmzJiByWTCaDQyZcoUACZNmsSkSZP44IMPMJvNTJs2jQMH\nDrh8z6ZNmzJ+/HgWLlyIyWSiS5cuNGjQwHOVFPEzuqqYiJ9q0aIFO3fuxGzWd3gRX6NucxERER+j\nlreIiIiPUctbRETExyi8RUREfIzCW0RExMcovEVERHyMwltERMTHKLxFRER8zP8Dgxo2ZVYQPygA\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oFEmZ5zq-llk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this plot, the dots represent the training loss and accuracy, and the solid lines are the validation loss and accuracy.\n",
        "\n",
        "Notice the training loss *decreases* with each epoch and the training accuracy *increases* with each epoch. This is expected when using a gradient descent optimizationâ€”it should minimize the desired quantity on every iteration.\n",
        "\n",
        "This isn't the case for the validation loss and accuracyâ€”they seem to peak after about twenty epochs. This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations *specific* to the training data that do not *generalize* to test data.\n",
        "\n",
        "For this particular case, we could prevent overfitting by simply stopping the training after twenty or so epochs. Later, you'll see how to do this automatically with a callback."
      ]
    },
    {
      "metadata": {
        "id": "NvoiEwiAWrWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ludwig (Open Source AutoML)"
      ]
    },
    {
      "metadata": {
        "id": "jbnbFKcTXNOn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Github Project URL**:  https://uber.github.io/ludwig/\n",
        "\n",
        "![alt text](https://user-images.githubusercontent.com/58792/52920000-f78d8c00-32bc-11e9-8e5e-adf53f1b8a37.png)"
      ]
    },
    {
      "metadata": {
        "id": "Aa-KnZKcfvkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Install Ludwig"
      ]
    },
    {
      "metadata": {
        "id": "Q3FrtesdfyV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1169
        },
        "outputId": "2a01a8ab-b163-4775-a101-5457c8c980d5"
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy #must restart colab runtime\n",
        "!pip install --upgrade scikit-image\n",
        "!pip install -q ludwig\n",
        "!python -m spacy download en "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.3MB 2.2MB/s \n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.16.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/06/d560630eb9e36d90d69fe57d9ff762d8f501664ce478b8a0ae132b3c3008/scikit_image-0.14.2-cp36-cp36m-manylinux1_x86_64.whl (25.3MB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25.3MB 833kB/s \n",
            "\u001b[?25hCollecting pillow>=4.3.0 (from scikit-image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0MB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.11.0)\n",
            "Collecting dask[array]>=1.0.0 (from scikit-image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/79/41d27ad703e782a422636dc8e0ce2f7624ef541b7219bd93a4af0b0d799c/dask-1.1.3-py2.py3-none-any.whl (703kB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 706kB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.2)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=1.0.0->scikit-image) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=1.0.0->scikit-image) (1.16.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image) (4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-image) (40.8.0)\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow, dask, scikit-image\n",
            "  Found existing installation: Pillow 4.1.1\n",
            "    Uninstalling Pillow-4.1.1:\n",
            "      Successfully uninstalled Pillow-4.1.1\n",
            "  Found existing installation: dask 0.20.2\n",
            "    Uninstalling dask-0.20.2:\n",
            "      Successfully uninstalled dask-0.20.2\n",
            "  Found existing installation: scikit-image 0.13.1\n",
            "    Uninstalling scikit-image-0.13.1:\n",
            "      Successfully uninstalled scikit-image-0.13.1\n",
            "Successfully installed dask-1.1.3 pillow-5.4.1 scikit-image-0.14.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "dask"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    8% |â–ˆâ–ˆâ–Š                             | 10kB 19.5MB/s eta 0:00:01\r\u001b[K    16% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 20kB 2.3MB/s eta 0:00:01\r\u001b[K    25% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 30kB 3.3MB/s eta 0:00:01\r\u001b[K    33% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 40kB 2.2MB/s eta 0:00:01\r\u001b[K    42% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 51kB 2.6MB/s eta 0:00:01\r\u001b[K    50% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 61kB 3.1MB/s eta 0:00:01\r\u001b[K    59% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K    67% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 81kB 4.0MB/s eta 0:00:01\r\u001b[K    76% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 92kB 4.5MB/s eta 0:00:01\r\u001b[K    84% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102kB 3.5MB/s eta 0:00:01\r\u001b[K    93% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 112kB 3.6MB/s eta 0:00:01\r\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 4.6MB/s \n",
            "\u001b[?25h  Building wheel for ludwig (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yVLSSAUViyiX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic Ideas"
      ]
    },
    {
      "metadata": {
        "id": "qHaRqAN5i1iV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* **Training Models**\n",
        "* **Prediction (Inference)**\n",
        "* **Datatypes**\n",
        " - binary\n",
        " - numerical\n",
        " - category\n",
        " - set\n",
        " - bag\n",
        " - sequence\n",
        " - text\n",
        " - timeseries\n",
        " - image\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "W3G5sZ3yo-yK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification of Book Title Categories (Project)"
      ]
    },
    {
      "metadata": {
        "id": "aIbXYrxU8ySd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "b882ab80-bd11-4cad-cc71-8bc12be6f1a0"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/uchidalab/book-dataset/master/Task1/book30-listing-train.csv\n",
        "!wget https://raw.githubusercontent.com/noahgift/recommendations/master/model_definition.yaml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-06 18:33:48--  https://raw.githubusercontent.com/uchidalab/book-dataset/master/Task1/book30-listing-train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9728786 (9.3M) [text/plain]\n",
            "Saving to: â€˜book30-listing-train.csvâ€™\n",
            "\n",
            "book30-listing-trai 100%[===================>]   9.28M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-03-06 18:33:48 (86.7 MB/s) - â€˜book30-listing-train.csvâ€™ saved [9728786/9728786]\n",
            "\n",
            "--2019-03-06 18:33:48--  https://raw.githubusercontent.com/noahgift/recommendations/master/model_definition.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180 [text/plain]\n",
            "Saving to: â€˜model_definition.yamlâ€™\n",
            "\n",
            "model_definition.ya 100%[===================>]     180  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-06 18:33:49 (22.2 MB/s) - â€˜model_definition.yamlâ€™ saved [180/180]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v-w5Zkzcumoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Ingest"
      ]
    },
    {
      "metadata": {
        "id": "Ef8dbaV4tHrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "94a149d2-4ca0-4bb7-e117-12cbfd59cb8c"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://media.githubusercontent.com/media/noahgift/recommendations/master/data/book30-listing-train-with-headers.csv\")\n",
        "df = df.drop(\"Unnamed: 0\", axis=1)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ASIN</th>\n",
              "      <th>FILENAME</th>\n",
              "      <th>IMAGE URL</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>CATEGORYID</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1404803335</td>\n",
              "      <td>1404803335.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/51UJnL3T...</td>\n",
              "      <td>Magnets: Pulling Together, Pushing Apart (Amaz...</td>\n",
              "      <td>Natalie M. Rosinsky</td>\n",
              "      <td>4</td>\n",
              "      <td>Children's Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1446276082</td>\n",
              "      <td>1446276082.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/51MGUKhk...</td>\n",
              "      <td>Energy Security (SAGE Library of International...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>Engineering &amp; Transportation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1491522666</td>\n",
              "      <td>1491522666.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/51qKvjsi...</td>\n",
              "      <td>An Amish Gathering: Life in Lancaster County</td>\n",
              "      <td>Beth Wiseman</td>\n",
              "      <td>9</td>\n",
              "      <td>Christian Books &amp; Bibles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>970096410</td>\n",
              "      <td>0970096410.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/51qoUENb...</td>\n",
              "      <td>City of Rocks Idaho: A Climber's Guide (Region...</td>\n",
              "      <td>Dave Bingham</td>\n",
              "      <td>26</td>\n",
              "      <td>Sports &amp; Outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8436808053</td>\n",
              "      <td>8436808053.jpg</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41aDW5pz...</td>\n",
              "      <td>Como vencer el insomnio. Tecnicas, reglas y co...</td>\n",
              "      <td>Choliz Montanes</td>\n",
              "      <td>11</td>\n",
              "      <td>Health, Fitness &amp; Dieting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ASIN        FILENAME  \\\n",
              "0  1404803335  1404803335.jpg   \n",
              "1  1446276082  1446276082.jpg   \n",
              "2  1491522666  1491522666.jpg   \n",
              "3   970096410  0970096410.jpg   \n",
              "4  8436808053  8436808053.jpg   \n",
              "\n",
              "                                           IMAGE URL  \\\n",
              "0  http://ecx.images-amazon.com/images/I/51UJnL3T...   \n",
              "1  http://ecx.images-amazon.com/images/I/51MGUKhk...   \n",
              "2  http://ecx.images-amazon.com/images/I/51qKvjsi...   \n",
              "3  http://ecx.images-amazon.com/images/I/51qoUENb...   \n",
              "4  http://ecx.images-amazon.com/images/I/41aDW5pz...   \n",
              "\n",
              "                                               TITLE               AUTHOR  \\\n",
              "0  Magnets: Pulling Together, Pushing Apart (Amaz...  Natalie M. Rosinsky   \n",
              "1  Energy Security (SAGE Library of International...                  NaN   \n",
              "2       An Amish Gathering: Life in Lancaster County         Beth Wiseman   \n",
              "3  City of Rocks Idaho: A Climber's Guide (Region...         Dave Bingham   \n",
              "4  Como vencer el insomnio. Tecnicas, reglas y co...      Choliz Montanes   \n",
              "\n",
              "   CATEGORYID                      CATEGORY  \n",
              "0           4              Children's Books  \n",
              "1          10  Engineering & Transportation  \n",
              "2           9      Christian Books & Bibles  \n",
              "3          26             Sports & Outdoors  \n",
              "4          11     Health, Fitness & Dieting  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "efw0icqJ_0Bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.to_csv(\"book30-listing-train-with-headers.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wR_L2OPkuqH4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### EDA"
      ]
    },
    {
      "metadata": {
        "id": "IUGz5U5duj-D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Columns**"
      ]
    },
    {
      "metadata": {
        "id": "KVYJIiwHuhiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "82b7a90f-0eed-456f-849f-58d72fa04a04"
      },
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ASIN', 'FILENAME', 'IMAGE URL', 'TITLE', 'AUTHOR', 'CATEGORYID',\n",
              "       'CATEGORY'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "ir0Viy2zuyr1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape**"
      ]
    },
    {
      "metadata": {
        "id": "-kaJsKyruyAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b139d22-63ee-40d7-d3f2-f75e25dcbd1f"
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51299, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "JJNSA3n0u3Zf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training w/Ludwig"
      ]
    },
    {
      "metadata": {
        "id": "bldBWuL2Nwmh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "b93bec4c-f589-4fb3-8463-18fbb4627b9f"
      },
      "cell_type": "code",
      "source": [
        "!head book30-listing-train-with-headers.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",ASIN,FILENAME,IMAGE URL,TITLE,AUTHOR,CATEGORYID,CATEGORY\n",
            "0,1404803335,1404803335.jpg,http://ecx.images-amazon.com/images/I/51UJnL3Tx6L.jpg,\"Magnets: Pulling Together, Pushing Apart (Amazing Science)\",Natalie M. Rosinsky,4,Children's Books\n",
            "1,1446276082,1446276082.jpg,http://ecx.images-amazon.com/images/I/51MGUKhkyhL.jpg,Energy Security (SAGE Library of International Security),,10,Engineering & Transportation\n",
            "2,1491522666,1491522666.jpg,http://ecx.images-amazon.com/images/I/51qKvjsi3ML.jpg,An Amish Gathering: Life in Lancaster County,Beth Wiseman,9,Christian Books & Bibles\n",
            "3,970096410,0970096410.jpg,http://ecx.images-amazon.com/images/I/51qoUENb1CL.jpg,City of Rocks Idaho: A Climber's Guide (Regional Rock Climbing Series),Dave Bingham,26,Sports & Outdoors\n",
            "4,8436808053,8436808053.jpg,http://ecx.images-amazon.com/images/I/41aDW5pzZBL.jpg,\"Como vencer el insomnio. Tecnicas, reglas y consejos practicos para dormir mejor (BIBLIOTECA PRACTICA) (Spanish Edition)\",Choliz Montanes,11,\"Health, Fitness & Dieting\"\n",
            "5,1848291388,1848291388.jpg,http://ecx.images-amazon.com/images/I/51Lpg7xmrBL.jpg,John Martin Littlejohn: An Enigma of Osteopathy,John O'Brien,16,Medical Books\n",
            "6,73402656,0073402656.jpg,http://ecx.images-amazon.com/images/I/51WccSzFUrL.jpg,Chemistry: The Molecular Nature of Matter and Change,Martin Silberberg,23,Science & Math\n",
            "7,323045979,0323045979.jpg,http://ecx.images-amazon.com/images/I/51rJir5EpnL.jpg,\"Mosby's Oncology Nursing Advisor: A Comprehensive Guide to Clinical Practice, 1e\",Susan Newton MS  RN  AOCN  AOCNS,16,Medical Books\n",
            "8,1847176968,1847176968.jpg,http://ecx.images-amazon.com/images/I/61KoC743OzL.jpg,Ireland's Wild Atlantic Way,Carsten Krieger,29,Travel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ous6EqC8Nocg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ea63b3b8-625d-4eb4-99df-0ea14882292c"
      },
      "cell_type": "code",
      "source": [
        "!cat model_definition.yaml"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_features:\n",
            "    -\n",
            "        name: TITLE\n",
            "        type: text\n",
            "        encoder: parallel_cnn\n",
            "        level: word\n",
            "\n",
            "output_features:\n",
            "    -\n",
            "        name: CATEGORY\n",
            "        type: category"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WpVA2fyXLRoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18997
        },
        "outputId": "a24ea754-289e-46d6-ce91-32641969fd19"
      },
      "cell_type": "code",
      "source": [
        "!ludwig experiment --data_csv book30-listing-train-with-headers.csv --model_definition_file model_definition.yaml\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " _         _        _      \n",
            "| |_  _ __| |_ __ _(_)__ _ \n",
            "| | || / _` \\ V  V / / _` |\n",
            "|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\n",
            "                     |___/ \n",
            "ludwig v0.1.0 - Experiment\n",
            "\n",
            "Experiment name: experiment\n",
            "Model name: run\n",
            "Output path: results/experiment_run_0\n",
            "\n",
            "ludwig_version: '0.1.0'\n",
            "command: ('/usr/local/bin/ludwig experiment --data_csv '\n",
            " 'book30-listing-train-with-headers.csv --model_definition_file '\n",
            " 'model_definition.yaml')\n",
            "dataset_type: 'book30-listing-train-with-headers.csv'\n",
            "model_definition: {   'combiner': {'type': 'concat'},\n",
            "    'input_features': [   {   'encoder': 'parallel_cnn',\n",
            "                              'level': 'word',\n",
            "                              'name': 'TITLE',\n",
            "                              'tied_weights': None,\n",
            "                              'type': 'text'}],\n",
            "    'output_features': [   {   'dependencies': [],\n",
            "                               'loss': {   'class_distance_temperature': 0,\n",
            "                                           'class_weights': 1,\n",
            "                                           'confidence_penalty': 0,\n",
            "                                           'distortion': 1,\n",
            "                                           'labels_smoothing': 0,\n",
            "                                           'negative_samples': 0,\n",
            "                                           'robust_lambda': 0,\n",
            "                                           'sampler': None,\n",
            "                                           'type': 'softmax_cross_entropy',\n",
            "                                           'unique': False,\n",
            "                                           'weight': 1},\n",
            "                               'name': 'CATEGORY',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'top_k': 3,\n",
            "                               'type': 'category'}],\n",
            "    'preprocessing': {   'bag': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': 10000,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': False},\n",
            "                         'binary': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_const'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'force_split': False,\n",
            "                         'image': {'missing_value_strategy': 'backfill'},\n",
            "                         'numerical': {   'fill_value': 0,\n",
            "                                          'missing_value_strategy': 'fill_with_const'},\n",
            "                         'sequence': {   'fill_value': '',\n",
            "                                         'format': 'space',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'sequence_length_limit': 256,\n",
            "                                         'unknown_symbol': '<UNK>'},\n",
            "                         'set': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'char_format': 'characters',\n",
            "                                     'char_most_common': 70,\n",
            "                                     'char_sequence_length_limit': 1024,\n",
            "                                     'fill_value': '',\n",
            "                                     'lowercase': True,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'word_format': 'space_punct',\n",
            "                                     'word_most_common': 20000,\n",
            "                                     'word_sequence_length_limit': 256},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'format': 'space',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256}},\n",
            "    'training': {   'batch_size': 128,\n",
            "                    'bucketing_field': None,\n",
            "                    'decay': False,\n",
            "                    'decay_rate': 0.96,\n",
            "                    'decay_steps': 10000,\n",
            "                    'dropout_rate': 0.0,\n",
            "                    'early_stop': 3,\n",
            "                    'epochs': 200,\n",
            "                    'gradient_clipping': None,\n",
            "                    'increase_batch_size_on_plateau': 0,\n",
            "                    'increase_batch_size_on_plateau_max': 512,\n",
            "                    'increase_batch_size_on_plateau_patience': 5,\n",
            "                    'increase_batch_size_on_plateau_rate': 2,\n",
            "                    'learning_rate': 0.001,\n",
            "                    'learning_rate_warmup_epochs': 5,\n",
            "                    'optimizer': {   'beta1': 0.9,\n",
            "                                     'beta2': 0.999,\n",
            "                                     'epsilon': 1e-08,\n",
            "                                     'type': 'adam'},\n",
            "                    'reduce_learning_rate_on_plateau': 0,\n",
            "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                    'regularization_lambda': 0,\n",
            "                    'regularizer': 'l2',\n",
            "                    'staircase': False,\n",
            "                    'validation_field': 'combined',\n",
            "                    'validation_measure': 'loss'}}\n",
            "\n",
            "Using full raw csv, no hdf5 and json file with the same name have been found\n",
            "Building dataset (it may take a while)\n",
            "Loading NLP pipeline\n",
            "Writing dataset\n",
            "Writing train set metadata with vocabulary\n",
            "Training set: 36059\n",
            "Validation set: 5042\n",
            "Test set: 10198\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ TRAINING â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•›\n",
            "\n",
            "2019-03-06 18:36:27.959991: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-03-06 18:36:27.960345: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x15c8100 executing computations on platform Host. Devices:\n",
            "2019-03-06 18:36:27.960387: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-03-06 18:36:28.022493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-03-06 18:36:28.023062: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x15c92e0 executing computations on platform CUDA. Devices:\n",
            "2019-03-06 18:36:28.023105: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-03-06 18:36:28.023572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 10.99GiB\n",
            "2019-03-06 18:36:28.023609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-03-06 18:36:37.541446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-03-06 18:36:37.541513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-03-06 18:36:37.541534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-03-06 18:36:37.541874: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-03-06 18:36:37.541950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10646 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "\n",
            "Epoch   1\n",
            "Training:   0% 0/282 [00:00<?, ?it/s]2019-03-06 18:36:38.317612: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Training: 100% 282/282 [00:19<00:00, 14.41it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.34it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 58.45it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 55.50it/s]\n",
            "Took 26.4015s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.3077 â”‚     0.0791 â”‚      0.1855 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.3093 â”‚     0.0768 â”‚      0.1813 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.3204 â”‚     0.0757 â”‚      0.1757 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   2\n",
            "Training: 100% 282/282 [00:17<00:00, 17.09it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.76it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 59.62it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.34it/s]\n",
            "Took 23.7353s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.2798 â”‚     0.0851 â”‚      0.2012 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.2836 â”‚     0.0841 â”‚      0.1987 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.2976 â”‚     0.0782 â”‚      0.1903 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   3\n",
            "Training: 100% 282/282 [00:17<00:00, 17.10it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.24it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.97it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 59.40it/s]\n",
            "Took 23.7937s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.2645 â”‚     0.0932 â”‚      0.2105 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.2703 â”‚     0.0908 â”‚      0.2061 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.2895 â”‚     0.0855 â”‚      0.1908 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   4\n",
            "Training: 100% 282/282 [00:17<00:00, 17.07it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.75it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 59.92it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 59.73it/s]\n",
            "Took 23.8098s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.2555 â”‚     0.0930 â”‚      0.2159 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.2681 â”‚     0.0863 â”‚      0.2075 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.2855 â”‚     0.0847 â”‚      0.1936 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   5\n",
            "Training: 100% 282/282 [00:17<00:00, 16.99it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.74it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.59it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.42it/s]\n",
            "Took 23.7983s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.2494 â”‚     0.0977 â”‚      0.2169 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.2630 â”‚     0.0896 â”‚      0.2100 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.2852 â”‚     0.0861 â”‚      0.1954 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   6\n",
            "Training: 100% 282/282 [00:17<00:00, 16.93it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.28it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.40it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 59.97it/s]\n",
            "Took 23.8555s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.2394 â”‚     0.1008 â”‚      0.2227 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.2568 â”‚     0.0928 â”‚      0.2156 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.2816 â”‚     0.0899 â”‚      0.2009 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   7\n",
            "Training: 100% 282/282 [00:17<00:00, 16.73it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.63it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.79it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 59.47it/s]\n",
            "Took 23.7988s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.2358 â”‚     0.1029 â”‚      0.2247 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.2589 â”‚     0.0930 â”‚      0.2130 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.2836 â”‚     0.0885 â”‚      0.2027 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch   8\n",
            "Training: 100% 282/282 [00:17<00:00, 16.85it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 59.38it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 60.19it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 59.76it/s]\n",
            "Took 23.8339s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.2308 â”‚     0.1033 â”‚      0.2277 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.2631 â”‚     0.0922 â”‚      0.2132 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.2841 â”‚     0.0906 â”‚      0.2068 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Last improvement of loss on combined happened 2 epochs ago\n",
            "\n",
            "\n",
            "Epoch   9\n",
            "Training: 100% 282/282 [00:17<00:00, 16.90it/s]\n",
            "Evaluation train: 100% 282/282 [00:04<00:00, 60.34it/s]\n",
            "Evaluation vali : 100% 40/40 [00:00<00:00, 61.08it/s]\n",
            "Evaluation test : 100% 80/80 [00:01<00:00, 60.57it/s]\n",
            "Took 23.7050s\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ CATEGORY   â”‚   loss â”‚   accuracy â”‚   hits_at_k â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ train      â”‚ 3.2243 â”‚     0.1059 â”‚      0.2311 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ vali       â”‚ 3.2594 â”‚     0.0960 â”‚      0.2114 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test       â”‚ 3.2824 â”‚     0.0904 â”‚      0.2051 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Last improvement of loss on combined happened 3 epochs ago\n",
            "\n",
            "EARLY STOPPING due to lack of validation improvement, it has been 3 epochs since last validation accuracy improvement\n",
            "\n",
            "Best validation model epoch: 6\n",
            "Best validation model loss on validation set combined: 3.2567949578763\n",
            "Best validation model loss on test set combined: 3.2816265680014234\n",
            "\n",
            "â•’â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ PREDICT â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•›\n",
            "\n",
            "Evaluation: 100% 80/80 [00:01<00:00, 58.31it/s]\n",
            "\n",
            "===== CATEGORY =====\n",
            "accuracy: 0.09040988429103745\n",
            "hits_at_k: 0.205138262404393\n",
            "loss: 3.2823813798077364\n",
            "overall_stats: { 'avg_f1_score_macro': 0.06090545474213738,\n",
            "  'avg_f1_score_micro': 0.09040988429103747,\n",
            "  'avg_f1_score_weighted': 0.0607478077092019,\n",
            "  'avg_precision_macro': 0.0644176382815366,\n",
            "  'avg_precision_micro': 0.09040988429103745,\n",
            "  'avg_precision_weighted': 0.09040988429103745,\n",
            "  'avg_recall_macro': 0.09169381528053014,\n",
            "  'avg_recall_micro': 0.09040988429103745,\n",
            "  'avg_recall_weighted': 0.09040988429103745,\n",
            "  'kappa_score': 0.05942286707355582,\n",
            "  'overall_accuracy': 0.09040988429103745}\n",
            "per_class_stats: {<UNK>: {   'accuracy': 1.0,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.0,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 0,\n",
            "    'false_omission_rate': 0.0,\n",
            "    'false_positive_rate': 0.0,\n",
            "    'false_positives': 0,\n",
            "    'hit_rate': 0,\n",
            "    'informedness': 0.0,\n",
            "    'markedness': 0.0,\n",
            "    'matthews_correlation_coefficient': 0,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 1.0,\n",
            "    'positive_predictive_value': 0,\n",
            "    'precision': 0,\n",
            "    'recall': 0,\n",
            "    'sensitivity': 0,\n",
            "    'specificity': 1.0,\n",
            "    'true_negative_rate': 1.0,\n",
            "    'true_negatives': 10198,\n",
            "    'true_positive_rate': 0,\n",
            "    'true_positives': 0},\n",
            "  Children's Books: {   'accuracy': 0.9494999019415572,\n",
            "    'f1_score': 0.061930783242258654,\n",
            "    'fall_out': 0.030880288750751994,\n",
            "    'false_discovery_rate': 0.9476923076923077,\n",
            "    'false_negative_rate': 0.9241071428571429,\n",
            "    'false_negatives': 207,\n",
            "    'false_omission_rate': 0.02096627164995446,\n",
            "    'false_positive_rate': 0.030880288750751994,\n",
            "    'false_positives': 308,\n",
            "    'hit_rate': 0.07589285714285714,\n",
            "    'informedness': 0.04501256839210521,\n",
            "    'markedness': 0.03134142065773782,\n",
            "    'matthews_correlation_coefficient': 0.037560056454459236,\n",
            "    'miss_rate': 0.9241071428571429,\n",
            "    'negative_predictive_value': 0.9790337283500455,\n",
            "    'positive_predictive_value': 0.052307692307692305,\n",
            "    'precision': 0.052307692307692305,\n",
            "    'recall': 0.07589285714285714,\n",
            "    'sensitivity': 0.07589285714285714,\n",
            "    'specificity': 0.969119711249248,\n",
            "    'true_negative_rate': 0.969119711249248,\n",
            "    'true_negatives': 9666,\n",
            "    'true_positive_rate': 0.07589285714285714,\n",
            "    'true_positives': 17},\n",
            "  Engineering & Transportation: {   'accuracy': 0.9555795253971366,\n",
            "    'f1_score': 0.029978586723768737,\n",
            "    'fall_out': 0.030369411530419166,\n",
            "    'false_discovery_rate': 0.9775641025641025,\n",
            "    'false_negative_rate': 0.9548387096774194,\n",
            "    'false_negatives': 148,\n",
            "    'false_omission_rate': 0.014970665587699772,\n",
            "    'false_positive_rate': 0.030369411530419166,\n",
            "    'false_positives': 305,\n",
            "    'hit_rate': 0.04516129032258064,\n",
            "    'informedness': 0.014791878792161484,\n",
            "    'markedness': 0.007465231848197584,\n",
            "    'matthews_correlation_coefficient': 0.010508320734252603,\n",
            "    'miss_rate': 0.9548387096774194,\n",
            "    'negative_predictive_value': 0.9850293344123002,\n",
            "    'positive_predictive_value': 0.022435897435897436,\n",
            "    'precision': 0.022435897435897436,\n",
            "    'recall': 0.04516129032258064,\n",
            "    'sensitivity': 0.04516129032258064,\n",
            "    'specificity': 0.9696305884695808,\n",
            "    'true_negative_rate': 0.9696305884695808,\n",
            "    'true_negatives': 9738,\n",
            "    'true_positive_rate': 0.04516129032258064,\n",
            "    'true_positives': 7},\n",
            "  Christian Books & Bibles: {   'accuracy': 0.9601882722102373,\n",
            "    'f1_score': 0.01932367149758454,\n",
            "    'fall_out': 0.034142490625616695,\n",
            "    'false_discovery_rate': 0.9885714285714285,\n",
            "    'false_negative_rate': 0.9375,\n",
            "    'false_negatives': 60,\n",
            "    'false_omission_rate': 0.006092607636068226,\n",
            "    'false_positive_rate': 0.034142490625616695,\n",
            "    'false_positives': 346,\n",
            "    'hit_rate': 0.0625,\n",
            "    'informedness': 0.028357509374383305,\n",
            "    'markedness': 0.005335963792503229,\n",
            "    'matthews_correlation_coefficient': 0.012301001718042272,\n",
            "    'miss_rate': 0.9375,\n",
            "    'negative_predictive_value': 0.9939073923639318,\n",
            "    'positive_predictive_value': 0.011428571428571429,\n",
            "    'precision': 0.011428571428571429,\n",
            "    'recall': 0.0625,\n",
            "    'sensitivity': 0.0625,\n",
            "    'specificity': 0.9658575093743833,\n",
            "    'true_negative_rate': 0.9658575093743833,\n",
            "    'true_negatives': 9788,\n",
            "    'true_positive_rate': 0.0625,\n",
            "    'true_positives': 4},\n",
            "  Sports & Outdoors: {   'accuracy': 0.9661698372229849,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.032881821751079676,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 10,\n",
            "    'false_omission_rate': 0.001013890297069886,\n",
            "    'false_positive_rate': 0.032881821751079676,\n",
            "    'false_positives': 335,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.032881821751079676,\n",
            "    'markedness': -0.001013890297069886,\n",
            "    'matthews_correlation_coefficient': -0.005773955318791468,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9989861097029301,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9671181782489203,\n",
            "    'true_negative_rate': 0.9671181782489203,\n",
            "    'true_negatives': 9853,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Health, Fitness & Dieting: {   'accuracy': 0.9627377917238674,\n",
            "    'f1_score': 0.005235602094240837,\n",
            "    'fall_out': 0.03356960031502265,\n",
            "    'false_discovery_rate': 0.9970760233918129,\n",
            "    'false_negative_rate': 0.975,\n",
            "    'false_negatives': 39,\n",
            "    'false_omission_rate': 0.0039569805194805685,\n",
            "    'false_positive_rate': 0.03356960031502265,\n",
            "    'false_positives': 341,\n",
            "    'hit_rate': 0.025,\n",
            "    'informedness': -0.00856960031502263,\n",
            "    'markedness': -0.001033003911293462,\n",
            "    'matthews_correlation_coefficient': -0.002975303454042867,\n",
            "    'miss_rate': 0.975,\n",
            "    'negative_predictive_value': 0.9960430194805194,\n",
            "    'positive_predictive_value': 0.0029239766081871343,\n",
            "    'precision': 0.0029239766081871343,\n",
            "    'recall': 0.025,\n",
            "    'sensitivity': 0.025,\n",
            "    'specificity': 0.9664303996849773,\n",
            "    'true_negative_rate': 0.9664303996849773,\n",
            "    'true_negatives': 9817,\n",
            "    'true_positive_rate': 0.025,\n",
            "    'true_positives': 1},\n",
            "  Medical Books: {   'accuracy': 0.9299862718180035,\n",
            "    'f1_score': 0.07989690721649484,\n",
            "    'fall_out': 0.031157117966588044,\n",
            "    'false_discovery_rate': 0.9074626865671642,\n",
            "    'false_negative_rate': 0.9297052154195011,\n",
            "    'false_negatives': 410,\n",
            "    'false_omission_rate': 0.041569502179864104,\n",
            "    'false_positive_rate': 0.031157117966588044,\n",
            "    'false_positives': 304,\n",
            "    'hit_rate': 0.07029478458049887,\n",
            "    'informedness': 0.03913766661391094,\n",
            "    'markedness': 0.05096781125297167,\n",
            "    'matthews_correlation_coefficient': 0.044662749633889935,\n",
            "    'miss_rate': 0.9297052154195011,\n",
            "    'negative_predictive_value': 0.9584304978201359,\n",
            "    'positive_predictive_value': 0.09253731343283582,\n",
            "    'precision': 0.09253731343283582,\n",
            "    'recall': 0.07029478458049887,\n",
            "    'sensitivity': 0.07029478458049887,\n",
            "    'specificity': 0.968842882033412,\n",
            "    'true_negative_rate': 0.968842882033412,\n",
            "    'true_negatives': 9453,\n",
            "    'true_positive_rate': 0.07029478458049887,\n",
            "    'true_positives': 31},\n",
            "  Science & Math: {   'accuracy': 0.9626397332810355,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.03660451422963695,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 8,\n",
            "    'false_omission_rate': 0.0008142493638676473,\n",
            "    'false_positive_rate': 0.03660451422963695,\n",
            "    'false_positives': 373,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.03660451422963695,\n",
            "    'markedness': -0.0008142493638676473,\n",
            "    'matthews_correlation_coefficient': -0.005459414110155727,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9991857506361324,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.963395485770363,\n",
            "    'true_negative_rate': 0.963395485770363,\n",
            "    'true_negatives': 9817,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Travel: {   'accuracy': 0.9690135320651108,\n",
            "    'f1_score': 0.006289308176100628,\n",
            "    'fall_out': 0.03032384690873402,\n",
            "    'false_discovery_rate': 0.9967741935483871,\n",
            "    'false_negative_rate': 0.875,\n",
            "    'false_negatives': 7,\n",
            "    'false_omission_rate': 0.0007079288025889641,\n",
            "    'false_positive_rate': 0.03032384690873402,\n",
            "    'false_positives': 309,\n",
            "    'hit_rate': 0.125,\n",
            "    'informedness': 0.09467615309126609,\n",
            "    'markedness': 0.002517877649024003,\n",
            "    'matthews_correlation_coefficient': 0.01543965575277066,\n",
            "    'miss_rate': 0.875,\n",
            "    'negative_predictive_value': 0.999292071197411,\n",
            "    'positive_predictive_value': 0.0032258064516129032,\n",
            "    'precision': 0.0032258064516129032,\n",
            "    'recall': 0.125,\n",
            "    'sensitivity': 0.125,\n",
            "    'specificity': 0.969676153091266,\n",
            "    'true_negative_rate': 0.969676153091266,\n",
            "    'true_negatives': 9881,\n",
            "    'true_positive_rate': 0.125,\n",
            "    'true_positives': 1},\n",
            "  Business & Money: {   'accuracy': 0.9679348891939596,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.03082965144820815,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 13,\n",
            "    'false_omission_rate': 0.0013152569809793402,\n",
            "    'false_positive_rate': 0.03082965144820815,\n",
            "    'false_positives': 314,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.03082965144820815,\n",
            "    'markedness': -0.0013152569809793402,\n",
            "    'matthews_correlation_coefficient': -0.006367802940450986,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9986847430190207,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9691703485517918,\n",
            "    'true_negative_rate': 0.9691703485517918,\n",
            "    'true_negatives': 9871,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Cookbooks, Food & Wine: {   'accuracy': 0.9616591488527162,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.03521888834235121,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 33,\n",
            "    'false_omission_rate': 0.0033536585365853133,\n",
            "    'false_positive_rate': 0.03521888834235121,\n",
            "    'false_positives': 358,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.03521888834235121,\n",
            "    'markedness': -0.0033536585365853133,\n",
            "    'matthews_correlation_coefficient': -0.010867940261998726,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9966463414634147,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9647811116576488,\n",
            "    'true_negative_rate': 0.9647811116576488,\n",
            "    'true_negatives': 9807,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Politics & Social Sciences: {   'accuracy': 0.9595018631104139,\n",
            "    'f1_score': 0.004819277108433736,\n",
            "    'fall_out': 0.03643884183572976,\n",
            "    'false_discovery_rate': 0.9973045822102425,\n",
            "    'false_negative_rate': 0.9772727272727273,\n",
            "    'false_negatives': 43,\n",
            "    'false_omission_rate': 0.00437569960313422,\n",
            "    'false_positive_rate': 0.03643884183572976,\n",
            "    'false_positives': 370,\n",
            "    'hit_rate': 0.022727272727272728,\n",
            "    'informedness': -0.013711569108457056,\n",
            "    'markedness': -0.0016802818133767605,\n",
            "    'matthews_correlation_coefficient': -0.004799927104217274,\n",
            "    'miss_rate': 0.9772727272727273,\n",
            "    'negative_predictive_value': 0.9956243003968658,\n",
            "    'positive_predictive_value': 0.0026954177897574125,\n",
            "    'precision': 0.0026954177897574125,\n",
            "    'recall': 0.022727272727272728,\n",
            "    'sensitivity': 0.022727272727272728,\n",
            "    'specificity': 0.9635611581642702,\n",
            "    'true_negative_rate': 0.9635611581642702,\n",
            "    'true_negatives': 9784,\n",
            "    'true_positive_rate': 0.022727272727272728,\n",
            "    'true_positives': 1},\n",
            "  Crafts, Hobbies & Home: {   'accuracy': 0.9663659541086488,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.03135443286809514,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 24,\n",
            "    'false_omission_rate': 0.002429395687822633,\n",
            "    'false_positive_rate': 0.03135443286809514,\n",
            "    'false_positives': 319,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.03135443286809514,\n",
            "    'markedness': -0.002429395687822633,\n",
            "    'matthews_correlation_coefficient': -0.008727675750385966,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9975706043121774,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9686455671319049,\n",
            "    'true_negative_rate': 0.9686455671319049,\n",
            "    'true_negatives': 9855,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Religion & Spirituality: {   'accuracy': 0.964600902137674,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.03511525257479153,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 3,\n",
            "    'false_omission_rate': 0.00030487804878043256,\n",
            "    'false_positive_rate': 0.03511525257479153,\n",
            "    'false_positives': 358,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.03511525257479153,\n",
            "    'markedness': -0.00030487804878043256,\n",
            "    'matthews_correlation_coefficient': -0.003271982531652095,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9996951219512196,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9648847474252085,\n",
            "    'true_negative_rate': 0.9648847474252085,\n",
            "    'true_negatives': 9837,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Literature & Fiction: {   'accuracy': 0.9330260835457933,\n",
            "    'f1_score': 0.09054593874833555,\n",
            "    'fall_out': 0.03334013050570961,\n",
            "    'false_discovery_rate': 0.9058171745152355,\n",
            "    'false_negative_rate': 0.9128205128205128,\n",
            "    'false_negatives': 356,\n",
            "    'false_omission_rate': 0.03618989529328043,\n",
            "    'false_positive_rate': 0.03334013050570961,\n",
            "    'false_positives': 327,\n",
            "    'hit_rate': 0.08717948717948718,\n",
            "    'informedness': 0.053839356673777594,\n",
            "    'markedness': 0.057992930191484104,\n",
            "    'matthews_correlation_coefficient': 0.055877563056532756,\n",
            "    'miss_rate': 0.9128205128205128,\n",
            "    'negative_predictive_value': 0.9638101047067196,\n",
            "    'positive_predictive_value': 0.09418282548476455,\n",
            "    'precision': 0.09418282548476455,\n",
            "    'recall': 0.08717948717948718,\n",
            "    'sensitivity': 0.08717948717948718,\n",
            "    'specificity': 0.9666598694942904,\n",
            "    'true_negative_rate': 0.9666598694942904,\n",
            "    'true_negatives': 9481,\n",
            "    'true_positive_rate': 0.08717948717948718,\n",
            "    'true_positives': 34},\n",
            "  Humor & Entertainment: {   'accuracy': 0.9677387723082957,\n",
            "    'f1_score': 0,\n",
            "    'fall_out': 0.0315014720314033,\n",
            "    'false_discovery_rate': 1.0,\n",
            "    'false_negative_rate': 1.0,\n",
            "    'false_negatives': 8,\n",
            "    'false_omission_rate': 0.0008099625392326004,\n",
            "    'false_positive_rate': 0.0315014720314033,\n",
            "    'false_positives': 321,\n",
            "    'hit_rate': 0.0,\n",
            "    'informedness': -0.0315014720314033,\n",
            "    'markedness': -0.0008099625392326004,\n",
            "    'matthews_correlation_coefficient': -0.005051238687304228,\n",
            "    'miss_rate': 1.0,\n",
            "    'negative_predictive_value': 0.9991900374607674,\n",
            "    'positive_predictive_value': 0.0,\n",
            "    'precision': 0.0,\n",
            "    'recall': 0.0,\n",
            "    'sensitivity': 0.0,\n",
            "    'specificity': 0.9684985279685967,\n",
            "    'true_negative_rate': 0.9684985279685967,\n",
            "    'true_negatives': 9869,\n",
            "    'true_positive_rate': 0.0,\n",
            "    'true_positives': 0},\n",
            "  Law: {   'accuracy': 0.9497940772700529,\n",
            "    'f1_score': 0.02661596958174905,\n",
            "    'fall_out': 0.034128330505937554,\n",
            "    'false_discovery_rate': 0.9799426934097422,\n",
            "    'false_negative_rate': 0.96045197740113,\n",
            "    'false_negatives': 170,\n",
            "    'false_omission_rate': 0.017260635597522556,\n",
            "    'false_positive_rate': 0.034128330505937554,\n",
            "    'false_positives': 342,\n",
            "    'hit_rate': 0.03954802259887006,\n",
            "    'informedness': 0.005419692092932582,\n",
            "    'markedness': 0.002796670992735395,\n",
            "    'matthews_correlation_coefficient': 0.003893211484861977,\n",
            "    'miss_rate': 0.96045197740113,\n",
            "    'negative_predictive_value': 0.9827393644024774,\n",
            "    'positive_predictive_value': 0.02005730659025788,\n",
            "    'precision': 0.02005730659025788,\n",
            "    'recall': 0.03954802259887006,\n",
            "    'sensitivity': 0.03954802259887006,\n",
            "    'specificity': 0.9658716694940624,\n",
            "    'true_negative_rate': 0.9658716694940624,\n",
            "    'true_negatives': 9679,\n",
            "    'true_positive_rate': 0.03954802259887006,\n",
            "    'true_positives': 7},\n",
            "  Computers & Technology: {   'accuracy': 0.952441655226515,\n",
            "    'f1_score': 0.039603960396039604,\n",
            "    'fall_out': 0.035295287333465875,\n",
            "    'false_discovery_rate': 0.9726027397260274,\n",
            "    'false_negative_rate': 0.9285714285714286,\n",
            "    'false_negatives': 130,\n",
            "    'false_omission_rate': 0.013220787145326929,\n",
            "    'false_positive_rate': 0.035295287333465875,\n",
            "    'false_positives': 355,\n",
            "    'hit_rate': 0.07142857142857142,\n",
            "    'informedness': 0.03613328409510563,\n",
            "    'markedness': 0.014176473128645561,\n",
            "    'matthews_correlation_coefficient': 0.022632775592577734,\n",
            "    'miss_rate': 0.9285714285714286,\n",
            "    'negative_predictive_value': 0.9867792128546731,\n",
            "    'positive_predictive_value': 0.0273972602739726,\n",
            "    'precision': 0.0273972602739726,\n",
            "    'recall': 0.07142857142857142,\n",
            "    'sensitivity': 0.07142857142857142,\n",
            "    'specificity': 0.9647047126665341,\n",
            "    'true_negative_rate': 0.9647047126665341,\n",
            "    'true_negatives': 9703,\n",
            "    'true_positive_rate': 0.07142857142857142,\n",
            "    'true_positives': 10},\n",
            "  Test Preparation: {   'accuracy': 0.9214551872916258,\n",
            "    'f1_score': 0.17337461300309598,\n",
            "    'fall_out': 0.025327053898482443,\n",
            "    'false_discovery_rate': 0.7423312883435582,\n",
            "    'false_negative_rate': 0.869362363919129,\n",
            "    'false_negatives': 559,\n",
            "    'false_omission_rate': 0.05662479740680715,\n",
            "    'false_positive_rate': 0.025327053898482443,\n",
            "    'false_positives': 242,\n",
            "    'hit_rate': 0.13063763608087092,\n",
            "    'informedness': 0.10531058218238853,\n",
            "    'markedness': 0.20104391424963453,\n",
            "    'matthews_correlation_coefficient': 0.14550619111864346,\n",
            "    'miss_rate': 0.869362363919129,\n",
            "    'negative_predictive_value': 0.9433752025931929,\n",
            "    'positive_predictive_value': 0.25766871165644173,\n",
            "    'precision': 0.25766871165644173,\n",
            "    'recall': 0.13063763608087092,\n",
            "    'sensitivity': 0.13063763608087092,\n",
            "    'specificity': 0.9746729461015176,\n",
            "    'true_negative_rate': 0.9746729461015176,\n",
            "    'true_negatives': 9313,\n",
            "    'true_positive_rate': 0.13063763608087092,\n",
            "    'true_positives': 84},\n",
            "  Arts & Photography: {   'accuracy': 0.9494018434987253,\n",
            "    'f1_score': 0.033707865168539325,\n",
            "    'fall_out': 0.031925540432345856,\n",
            "    'false_discovery_rate': 0.9725609756097561,\n",
            "    'false_negative_rate': 0.9563106796116505,\n",
            "    'false_negatives': 197,\n",
            "    'false_omission_rate': 0.01995947315096247,\n",
            "    'false_positive_rate': 0.031925540432345856,\n",
            "    'false_positives': 319,\n",
            "    'hit_rate': 0.043689320388349516,\n",
            "    'informedness': 0.01176377995600375,\n",
            "    'markedness': 0.007479551239281346,\n",
            "    'matthews_correlation_coefficient': 0.009380180965661622,\n",
            "    'miss_rate': 0.9563106796116505,\n",
            "    'negative_predictive_value': 0.9800405268490375,\n",
            "    'positive_predictive_value': 0.027439024390243903,\n",
            "    'precision': 0.027439024390243903,\n",
            "    'recall': 0.043689320388349516,\n",
            "    'sensitivity': 0.043689320388349516,\n",
            "    'specificity': 0.9680744595676541,\n",
            "    'true_negative_rate': 0.9680744595676541,\n",
            "    'true_negatives': 9673,\n",
            "    'true_positive_rate': 0.043689320388349516,\n",
            "    'true_positives': 9},\n",
            "  Parenting & Relationships: {   'accuracy': 0.9264561678760541,\n",
            "    'f1_score': 0.12383177570093457,\n",
            "    'fall_out': 0.0331377997324277,\n",
            "    'false_discovery_rate': 0.8586666666666667,\n",
            "    'false_negative_rate': 0.8898128898128899,\n",
            "    'false_negatives': 428,\n",
            "    'false_omission_rate': 0.04357121042451395,\n",
            "    'false_positive_rate': 0.0331377997324277,\n",
            "    'false_positives': 322,\n",
            "    'hit_rate': 0.1101871101871102,\n",
            "    'informedness': 0.07704931045468255,\n",
            "    'markedness': 0.09776212290881947,\n",
            "    'matthews_correlation_coefficient': 0.08679000033823284,\n",
            "    'miss_rate': 0.8898128898128899,\n",
            "    'negative_predictive_value': 0.956428789575486,\n",
            "    'positive_predictive_value': 0.14133333333333334,\n",
            "    'precision': 0.14133333333333334,\n",
            "    'recall': 0.1101871101871102,\n",
            "    'sensitivity': 0.1101871101871102,\n",
            "    'specificity': 0.9668622002675723,\n",
            "    'true_negative_rate': 0.9668622002675723,\n",
            "    'true_negatives': 9395,\n",
            "    'true_positive_rate': 0.1101871101871102,\n",
            "    'true_positives': 53},\n",
            "  Romance: {   'accuracy': 0.8741910178466366,\n",
            "    'f1_score': 0.14409606404269512,\n",
            "    'fall_out': 0.026097534004202116,\n",
            "    'false_discovery_rate': 0.686046511627907,\n",
            "    'false_negative_rate': 0.9064935064935065,\n",
            "    'false_negatives': 1047,\n",
            "    'false_omission_rate': 0.10625126852039779,\n",
            "    'false_positive_rate': 0.026097534004202116,\n",
            "    'false_positives': 236,\n",
            "    'hit_rate': 0.09350649350649351,\n",
            "    'informedness': 0.06740895950229131,\n",
            "    'markedness': 0.20770221985169535,\n",
            "    'matthews_correlation_coefficient': 0.11832578132646722,\n",
            "    'miss_rate': 0.9064935064935065,\n",
            "    'negative_predictive_value': 0.8937487314796022,\n",
            "    'positive_predictive_value': 0.313953488372093,\n",
            "    'precision': 0.313953488372093,\n",
            "    'recall': 0.09350649350649351,\n",
            "    'sensitivity': 0.09350649350649351,\n",
            "    'specificity': 0.9739024659957979,\n",
            "    'true_negative_rate': 0.9739024659957979,\n",
            "    'true_negatives': 8807,\n",
            "    'true_positive_rate': 0.09350649350649351,\n",
            "    'true_positives': 108},\n",
            "  History: {   'accuracy': 0.9407727005295156,\n",
            "    'f1_score': 0.08206686930091187,\n",
            "    'fall_out': 0.030993618960802216,\n",
            "    'false_discovery_rate': 0.9189189189189189,\n",
            "    'false_negative_rate': 0.916923076923077,\n",
            "    'false_negatives': 298,\n",
            "    'false_omission_rate': 0.030207805372529095,\n",
            "    'false_positive_rate': 0.030993618960802216,\n",
            "    'false_positives': 306,\n",
            "    'hit_rate': 0.08307692307692308,\n",
            "    'informedness': 0.05208330411612083,\n",
            "    'markedness': 0.050873275708551935,\n",
            "    'matthews_correlation_coefficient': 0.05147473448315956,\n",
            "    'miss_rate': 0.916923076923077,\n",
            "    'negative_predictive_value': 0.9697921946274709,\n",
            "    'positive_predictive_value': 0.08108108108108109,\n",
            "    'precision': 0.08108108108108109,\n",
            "    'recall': 0.08307692307692308,\n",
            "    'sensitivity': 0.08307692307692308,\n",
            "    'specificity': 0.9690063810391978,\n",
            "    'true_negative_rate': 0.9690063810391978,\n",
            "    'true_negatives': 9567,\n",
            "    'true_positive_rate': 0.08307692307692308,\n",
            "    'true_positives': 27},\n",
            "  Comics & Graphic Novels: {   'accuracy': 0.9567562267111198,\n",
            "    'f1_score': 0.2194690265486726,\n",
            "    'fall_out': 0.02855711422845686,\n",
            "    'false_discovery_rate': 0.8213256484149856,\n",
            "    'false_negative_rate': 0.7155963302752293,\n",
            "    'false_negatives': 156,\n",
            "    'false_omission_rate': 0.01583595574053398,\n",
            "    'false_positive_rate': 0.02855711422845686,\n",
            "    'false_positives': 285,\n",
            "    'hit_rate': 0.28440366972477066,\n",
            "    'informedness': 0.25584655549631385,\n",
            "    'markedness': 0.16283839584448034,\n",
            "    'matthews_correlation_coefficient': 0.2041118386555654,\n",
            "    'miss_rate': 0.7155963302752293,\n",
            "    'negative_predictive_value': 0.984164044259466,\n",
            "    'positive_predictive_value': 0.1786743515850144,\n",
            "    'precision': 0.1786743515850144,\n",
            "    'recall': 0.28440366972477066,\n",
            "    'sensitivity': 0.28440366972477066,\n",
            "    'specificity': 0.9714428857715431,\n",
            "    'true_negative_rate': 0.9714428857715431,\n",
            "    'true_negatives': 9695,\n",
            "    'true_positive_rate': 0.28440366972477066,\n",
            "    'true_positives': 62},\n",
            "  Reference: {   'accuracy': 0.9580309864679349,\n",
            "    'f1_score': 0.03603603603603603,\n",
            "    'fall_out': 0.034039184642786435,\n",
            "    'false_discovery_rate': 0.9772727272727273,\n",
            "    'false_negative_rate': 0.9130434782608696,\n",
            "    'false_negatives': 84,\n",
            "    'false_omission_rate': 0.00853138330286407,\n",
            "    'false_positive_rate': 0.034039184642786435,\n",
            "    'false_positives': 344,\n",
            "    'hit_rate': 0.08695652173913043,\n",
            "    'informedness': 0.05291733709634405,\n",
            "    'markedness': 0.014195889424408747,\n",
            "    'matthews_correlation_coefficient': 0.027408186113894065,\n",
            "    'miss_rate': 0.9130434782608696,\n",
            "    'negative_predictive_value': 0.9914686166971359,\n",
            "    'positive_predictive_value': 0.022727272727272728,\n",
            "    'precision': 0.022727272727272728,\n",
            "    'recall': 0.08695652173913043,\n",
            "    'sensitivity': 0.08695652173913043,\n",
            "    'specificity': 0.9659608153572136,\n",
            "    'true_negative_rate': 0.9659608153572136,\n",
            "    'true_negatives': 9762,\n",
            "    'true_positive_rate': 0.08695652173913043,\n",
            "    'true_positives': 8},\n",
            "  Teen & Young Adult: {   'accuracy': 0.9467542655422632,\n",
            "    'f1_score': 0.04903677758318739,\n",
            "    'fall_out': 0.03406472297364993,\n",
            "    'false_discovery_rate': 0.96045197740113,\n",
            "    'false_negative_rate': 0.935483870967742,\n",
            "    'false_negatives': 203,\n",
            "    'false_omission_rate': 0.02062169849654616,\n",
            "    'false_positive_rate': 0.03406472297364993,\n",
            "    'false_positives': 340,\n",
            "    'hit_rate': 0.06451612903225806,\n",
            "    'informedness': 0.030451406058608077,\n",
            "    'markedness': 0.018926324102323866,\n",
            "    'matthews_correlation_coefficient': 0.02400694025561542,\n",
            "    'miss_rate': 0.935483870967742,\n",
            "    'negative_predictive_value': 0.9793783015034538,\n",
            "    'positive_predictive_value': 0.03954802259887006,\n",
            "    'precision': 0.03954802259887006,\n",
            "    'recall': 0.06451612903225806,\n",
            "    'sensitivity': 0.06451612903225806,\n",
            "    'specificity': 0.9659352770263501,\n",
            "    'true_negative_rate': 0.9659352770263501,\n",
            "    'true_negatives': 9641,\n",
            "    'true_positive_rate': 0.06451612903225806,\n",
            "    'true_positives': 14},\n",
            "  Self-Help: {   'accuracy': 0.8597764267503432,\n",
            "    'f1_score': 0.10062893081761005,\n",
            "    'fall_out': 0.026990704446186564,\n",
            "    'false_discovery_rate': 0.7507788161993769,\n",
            "    'false_negative_rate': 0.9369582348305753,\n",
            "    'false_negatives': 1189,\n",
            "    'false_omission_rate': 0.12038068239343935,\n",
            "    'false_positive_rate': 0.026990704446186564,\n",
            "    'false_positives': 241,\n",
            "    'hit_rate': 0.06304176516942474,\n",
            "    'informedness': 0.03605106072323827,\n",
            "    'markedness': 0.12884050140718362,\n",
            "    'matthews_correlation_coefficient': 0.06815303910936646,\n",
            "    'miss_rate': 0.9369582348305753,\n",
            "    'negative_predictive_value': 0.8796193176065606,\n",
            "    'positive_predictive_value': 0.24922118380062305,\n",
            "    'precision': 0.24922118380062305,\n",
            "    'recall': 0.06304176516942474,\n",
            "    'sensitivity': 0.06304176516942474,\n",
            "    'specificity': 0.9730092955538134,\n",
            "    'true_negative_rate': 0.9730092955538134,\n",
            "    'true_negatives': 8688,\n",
            "    'true_positive_rate': 0.06304176516942474,\n",
            "    'true_positives': 80},\n",
            "  Calendars: {   'accuracy': 0.8386938615414787,\n",
            "    'f1_score': 0.1948115516397455,\n",
            "    'fall_out': 0.014044612297887449,\n",
            "    'false_discovery_rate': 0.37421383647798745,\n",
            "    'false_negative_rate': 0.8846376811594203,\n",
            "    'false_negatives': 1526,\n",
            "    'false_omission_rate': 0.1544534412955466,\n",
            "    'false_positive_rate': 0.014044612297887449,\n",
            "    'false_positives': 119,\n",
            "    'hit_rate': 0.11536231884057971,\n",
            "    'informedness': 0.10131770654269223,\n",
            "    'markedness': 0.47133272222646605,\n",
            "    'matthews_correlation_coefficient': 0.2185276880271912,\n",
            "    'miss_rate': 0.8846376811594203,\n",
            "    'negative_predictive_value': 0.8455465587044534,\n",
            "    'positive_predictive_value': 0.6257861635220126,\n",
            "    'precision': 0.6257861635220126,\n",
            "    'recall': 0.11536231884057971,\n",
            "    'sensitivity': 0.11536231884057971,\n",
            "    'specificity': 0.9859553877021126,\n",
            "    'true_negative_rate': 0.9859553877021126,\n",
            "    'true_negatives': 8354,\n",
            "    'true_positive_rate': 0.11536231884057971,\n",
            "    'true_positives': 199},\n",
            "  Science Fiction & Fantasy: {   'accuracy': 0.940184349872524,\n",
            "    'f1_score': 0.0729483282674772,\n",
            "    'fall_out': 0.02893694791349377,\n",
            "    'false_discovery_rate': 0.9223300970873787,\n",
            "    'false_negative_rate': 0.9312320916905444,\n",
            "    'false_negatives': 325,\n",
            "    'false_omission_rate': 0.03286479927191832,\n",
            "    'false_positive_rate': 0.02893694791349377,\n",
            "    'false_positives': 285,\n",
            "    'hit_rate': 0.06876790830945559,\n",
            "    'informedness': 0.0398309603959619,\n",
            "    'markedness': 0.044805103640703114,\n",
            "    'matthews_correlation_coefficient': 0.04224488499984121,\n",
            "    'miss_rate': 0.9312320916905444,\n",
            "    'negative_predictive_value': 0.9671352007280817,\n",
            "    'positive_predictive_value': 0.07766990291262135,\n",
            "    'precision': 0.07766990291262135,\n",
            "    'recall': 0.06876790830945559,\n",
            "    'sensitivity': 0.06876790830945559,\n",
            "    'specificity': 0.9710630520865062,\n",
            "    'true_negative_rate': 0.9710630520865062,\n",
            "    'true_negatives': 9564,\n",
            "    'true_positive_rate': 0.06876790830945559,\n",
            "    'true_positives': 24},\n",
            "  Mystery, Thriller & Suspense: {   'accuracy': 0.9052755442243577,\n",
            "    'f1_score': 0.12021857923497267,\n",
            "    'fall_out': 0.02871675320546785,\n",
            "    'false_discovery_rate': 0.8041543026706232,\n",
            "    'false_negative_rate': 0.9132720105124836,\n",
            "    'false_negatives': 695,\n",
            "    'false_omission_rate': 0.07047966737653377,\n",
            "    'false_positive_rate': 0.02871675320546785,\n",
            "    'false_positives': 271,\n",
            "    'hit_rate': 0.08672798948751642,\n",
            "    'informedness': 0.05801123628204863,\n",
            "    'markedness': 0.12536602995284296,\n",
            "    'matthews_correlation_coefficient': 0.08527976539213014,\n",
            "    'miss_rate': 0.9132720105124836,\n",
            "    'negative_predictive_value': 0.9295203326234662,\n",
            "    'positive_predictive_value': 0.19584569732937684,\n",
            "    'precision': 0.19584569732937684,\n",
            "    'recall': 0.08672798948751642,\n",
            "    'sensitivity': 0.08672798948751642,\n",
            "    'specificity': 0.9712832467945322,\n",
            "    'true_negative_rate': 0.9712832467945322,\n",
            "    'true_negatives': 9166,\n",
            "    'true_positive_rate': 0.08672798948751642,\n",
            "    'true_positives': 66},\n",
            "  Biographies & Memoirs: {   'accuracy': 0.8841929790154932,\n",
            "    'f1_score': 0.11269722013523667,\n",
            "    'fall_out': 0.030467309985904856,\n",
            "    'false_discovery_rate': 0.7893258426966292,\n",
            "    'false_negative_rate': 0.9230769230769231,\n",
            "    'false_negatives': 900,\n",
            "    'false_omission_rate': 0.09144482828693357,\n",
            "    'false_positive_rate': 0.030467309985904856,\n",
            "    'false_positives': 281,\n",
            "    'hit_rate': 0.07692307692307693,\n",
            "    'informedness': 0.04645576693717213,\n",
            "    'markedness': 0.11922932901643724,\n",
            "    'matthews_correlation_coefficient': 0.07442371880565375,\n",
            "    'miss_rate': 0.9230769230769231,\n",
            "    'negative_predictive_value': 0.9085551717130664,\n",
            "    'positive_predictive_value': 0.21067415730337077,\n",
            "    'precision': 0.21067415730337077,\n",
            "    'recall': 0.07692307692307693,\n",
            "    'sensitivity': 0.07692307692307693,\n",
            "    'specificity': 0.9695326900140951,\n",
            "    'true_negative_rate': 0.9695326900140951,\n",
            "    'true_negatives': 8942,\n",
            "    'true_positive_rate': 0.07692307692307693,\n",
            "    'true_positives': 75}}\n",
            "\n",
            "Finished: experiment_run\n",
            "Saved to: results/experiment_run_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "21q0EGuO5dpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "0ExRA9v55cr6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ggjuE4es7SDH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GCP AutoML\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ydR9SXDKAXvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![GCP AutoML](https://user-images.githubusercontent.com/58792/45260264-134c4800-b397-11e8-9832-fd56a8eeaa3c.png)\n",
        "\n",
        "\n",
        "**[GCP AutoML Products](https://cloud.google.com/automl/)**\n",
        "\n",
        "*  [AutoML Vision](https://cloud.google.com/vision/automl/docs/)\n",
        "*  [AutoML Natural Language](https://cloud.google.com/natural-language/automl/docs/)\n",
        "*  [AutoML Translation](https://cloud.google.com/translate/automl/docs/)\n"
      ]
    },
    {
      "metadata": {
        "id": "QYU7DysIifKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GCP AutoML Demo\n"
      ]
    },
    {
      "metadata": {
        "id": "MAtZVZgRin7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training to recognize flowers\n",
        "\n",
        "![upload_data](https://user-images.githubusercontent.com/58792/45438280-94dbf880-b66b-11e8-850d-e7d2a32c45c8.png)\n",
        "\n",
        "![train](https://user-images.githubusercontent.com/58792/45438281-94dbf880-b66b-11e8-9951-80202c581b0c.png)\n",
        "\n",
        "![predict](https://user-images.githubusercontent.com/58792/45439236-1fbdf280-b66e-11e8-9f51-d92d26a63c64.png)"
      ]
    },
    {
      "metadata": {
        "id": "tho4WI7ikZb0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GCP Vision API"
      ]
    },
    {
      "metadata": {
        "id": "desIuhDTkogY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vision/\n",
        "\n",
        "![Vision API](https://cloud.google.com/images/products/vision/image-search.svg)\n",
        "\n",
        "* [Step 1:  Enable API](https://cloud.google.com/vision/docs/before-you-begin)"
      ]
    },
    {
      "metadata": {
        "id": "emW2WhQYn5e7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "hPWO_zyRopXN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load Google Credentials with GDrive\n"
      ]
    },
    {
      "metadata": {
        "id": "XI73HZNLobp4",
        "colab_type": "code",
        "outputId": "aa33d89e-a20e-4e7a-bc37-d7f2020d9d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UNyzZwgmoxwm",
        "colab_type": "code",
        "outputId": "5859b7ff-0758-40e9-be6a-3a4fdec60dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os;os.listdir(\"/content/gdrive/My Drive/awsml\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kaggle.json', 'credentials', 'config', 'cloudai-7ab42a4d8a43.json']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "k7LLMTLNuxgI",
        "colab_type": "code",
        "outputId": "0a7f7fc7-8489-40dc-8ed9-804d06d985f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -la /content/gdrive/My\\ Drive/awsml"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "-rw------- 1 root root 2305 Feb 22 23:47 cloudai-7ab42a4d8a43.json\n",
            "-rw------- 1 root root   43 Nov 22 00:05 config\n",
            "-rw------- 1 root root  117 Nov 22 00:01 credentials\n",
            "-rw------- 1 root root   64 Nov 21 22:24 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w2f1xHUMwCJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install cloud vision Api"
      ]
    },
    {
      "metadata": {
        "id": "sRlg-4kPk1Wl",
        "colab_type": "code",
        "outputId": "cab59993-d3d0-4002-fc2d-f047e8cd6c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!export GOOGLE_APPLICATION_CREDENTIALS=\"/content/gdrive/My\\ Drive/awsml/cloudai-7ab42a4d8a43.json\"\n",
        "!gcloud auth activate-service-account --key-file /content/gdrive/My\\ Drive/awsml/cloudai-7ab42a4d8a43.json\n",
        "!pip install --upgrade -q google-cloud-vision"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Activated service account credentials for: [pragai@cloudai-194723.iam.gserviceaccount.com]\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 389kB 8.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oIJgeisov5kb",
        "colab_type": "code",
        "outputId": "b819c99d-f437-4dbd-80cc-878714d6f754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/content/gdrive/My Drive/awsml/cloudai-7ab42a4d8a43.json\"\n",
        "\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "\n",
        "# Instantiates a client\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# The name of the image file to annotate\n",
        "file_name = 'wakeupcat.jpg'\n",
        "\n",
        "# Loads the image into memory\n",
        "with io.open(file_name, 'rb') as image_file:\n",
        "    content = image_file.read()\n",
        "\n",
        "image = types.Image(content=content)\n",
        "\n",
        "# Performs label detection on the image file\n",
        "response = client.label_detection(image=image)\n",
        "labels = response.label_annotations\n",
        "\n",
        "print('Labels:')\n",
        "for label in labels:\n",
        "    print(label.description)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels:\n",
            "Cat\n",
            "Whiskers\n",
            "Small to medium-sized cats\n",
            "Felidae\n",
            "Fur\n",
            "Nose\n",
            "Ear\n",
            "Snout\n",
            "Carnivore\n",
            "Eye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tBbAdZspTRGW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n"
      ]
    },
    {
      "metadata": {
        "id": "PjOc_DzTTU8v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   [Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/)\n",
        "\n"
      ]
    }
  ]
}